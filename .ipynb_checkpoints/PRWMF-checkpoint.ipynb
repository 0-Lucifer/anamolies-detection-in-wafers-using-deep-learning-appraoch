{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8978f75d-dc9e-4443-b436-2c792176934d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692bece4-20d0-44c5-a80c-360864115ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5776659-cd5e-4188-8c58-10f677464441",
   "metadata": {},
   "source": [
    "## Config Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0073570-e4a6-47b0-a9fa-8ddfee93135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, \"dataset\")\n",
    "PROCESSED_DIR = os.path.join(DATASET_DIR, \"processed\")\n",
    "FIGURES_DIR = os.path.join(ROOT_DIR, \"figures\")\n",
    "\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "PKL_PATH = os.path.join(DATASET_DIR, \"LSWMD.pkl\")\n",
    "H5_PATH = os.path.join(PROCESSED_DIR, \"wm811k_processed_224.h5\")\n",
    "\n",
    "IMG_SIZE = 224\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Classes in the exact order most papers use\n",
    "CLASSES = ['none', 'Loc', 'Edge-Loc', 'Center', 'Edge-Ring', 'Scratch', 'Random', 'Donut', 'Near-full'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505d024-ff57-455a-bde3-3ee74b23d6e3",
   "metadata": {},
   "source": [
    "## Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb84034-000d-4228-982f-f1e792b120ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LSWMD.pkl...\n",
      "Total wafers in raw pickle: 811457\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811457 entries, 0 to 811456\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   waferMap        811457 non-null  object \n",
      " 1   dieSize         811457 non-null  float64\n",
      " 2   lotName         811457 non-null  object \n",
      " 3   waferIndex      811457 non-null  float64\n",
      " 4   trianTestLabel  811457 non-null  object \n",
      " 5   failureType     811457 non-null  object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 37.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Loading LSWMD.pkl...\")\n",
    "data = pd.read_pickle(PKL_PATH)         \n",
    "\n",
    "print(f\"Total wafers in raw pickle: {len(data)}\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80acbc45-552c-4202-b429-979d70ae3db9",
   "metadata": {},
   "source": [
    "## Convert to DataFrame for easier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd97666-bad0-4f66-8c13-cec02833c671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully labeled samples: 172950\n",
      "\n",
      "Label distribution:\n",
      "failureType\n",
      "none         147431\n",
      "Edge-Ring      9680\n",
      "Edge-Loc       5189\n",
      "Center         4294\n",
      "Loc            3593\n",
      "Scratch        1193\n",
      "Random          866\n",
      "Donut           555\n",
      "Near-full       149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Vectorized extraction\n",
    "def extract_label(ft):\n",
    "    if hasattr(ft, 'ndim') and ft.ndim == 2 and ft.size > 0:\n",
    "        val = ft[0][0]\n",
    "        if val not in ('', b''):\n",
    "            return str(val)      # force to Python str in case it's bytes\n",
    "    return np.nan\n",
    "\n",
    "# Apply the extraction\n",
    "data['failureType'] = data['failureType'].apply(extract_label)\n",
    "\n",
    "# Keep only the fully labeled ones\n",
    "df = data[data['failureType'].notna()].copy()\n",
    "\n",
    "# Add the extra columns you wanted\n",
    "df['shape'] = df['waferMap'].apply(lambda x: x.shape)\n",
    "df = df.reset_index().rename(columns={'index': 'idx'})   # 'idx' = original row number in the pickle\n",
    "\n",
    "print(f\"Fully labeled samples: {len(df)}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['failureType'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff71eb-b539-4fc1-8f6d-b89f5ecd10f9",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2374328-b2f2-448c-b94b-1fab9ef63fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(CLASSES)\n",
    "df['label_int'] = le.transform(df['failureType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887da38-59f1-4357-a1b7-8f5597f0f638",
   "metadata": {},
   "source": [
    "## Lot-based train/val/test split (80/10/10) - NO LEAKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37e3e22-8bf4-4e5c-8b73-b745a537301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=SEED)\n",
    "train_idx, temp_idx = next(gss.split(df, groups=df['lotName']))\n",
    "\n",
    "df_train = df.iloc[train_idx].copy()\n",
    "df_temp = df.iloc[temp_idx].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec3238-869a-4500-9143-6f2a4a6777ca",
   "metadata": {},
   "source": [
    "## Second split on remaining 20% → val/test 10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9981c2e2-94e5-483d-a2b4-ec5cd0de5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 138503 | Val: 16834 | Test: 17613\n",
      "Unique lots - Train: 8609, Val: 1076, Test: 1077\n"
     ]
    }
   ],
   "source": [
    "gss2 = GroupShuffleSplit(n_splits=1, train_size=0.5, random_state=SEED+1)\n",
    "val_idx, test_idx = next(gss2.split(df_temp, groups=df_temp['lotName']))\n",
    "\n",
    "df_val = df_temp.iloc[val_idx].copy()\n",
    "df_test = df_temp.iloc[test_idx].copy()\n",
    "\n",
    "print(f\"Train: {len(df_train)} | Val: {len(df_val)} | Test: {len(df_test)}\")\n",
    "print(f\"Unique lots - Train: {df_train['lotName'].nunique()}, Val: {df_val['lotName'].nunique()}, Test: {df_test['lotName'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98cbe43-0699-4361-93d1-c76eaffd206c",
   "metadata": {},
   "source": [
    "## Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c52c95-b484-4d51-8203-5f989f38adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_wafer(wafer_map):\n",
    "    \"\"\"\n",
    "    Input: raw wafer_map (H, W) with values 0,1,2\n",
    "    Output: (224,224,3) uint8 image ready for ImageNet-pretrained models\n",
    "    \"\"\"\n",
    "    # Convert to binary defect map: only defective dies = 255, everything else = 0\n",
    "    defect = np.zeros(wafer_map.shape, dtype=np.uint8)\n",
    "    defect[wafer_map == 2] = 255\n",
    "    \n",
    "    # Resize with CUBIC (as requested, though NEAREST is also popular for binary)\n",
    "    resized = cv2.resize(defect, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to 3-channel\n",
    "    resized_3ch = np.repeat(resized[:, :, np.newaxis], 3, axis=2)\n",
    "    \n",
    "    return resized_3ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38760a45-ad07-46f7-9000-02de7da1d459",
   "metadata": {},
   "source": [
    "## Process and save to HDF5 (uint8 to keep size ~25-30GB total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1462e2-dc1c-4b53-8ec6-9b8746f0cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing and saving to HDF5 (this will take 30-60 minutes)...\n",
      "TRAIN saved: (138503, 224, 224, 3) images, 20.8 GB\n",
      "VAL saved: (16834, 224, 224, 3) images, 2.5 GB\n",
      "TEST saved: (17613, 224, 224, 3) images, 2.7 GB\n",
      "All done! HDF5 saved to: C:\\Users\\user\\Desktop\\project 465\\dataset\\processed\\wm811k_processed_224.h5\n"
     ]
    }
   ],
   "source": [
    "def save_split_to_h5(df_split, split_name, h5_file):\n",
    "    images = []\n",
    "    labels = []\n",
    "    lotnames = []\n",
    "    original_indices = []  # to trace back if needed\n",
    "    \n",
    "    for _, row in df_split.iterrows():\n",
    "        img = preprocess_wafer(row['waferMap'])\n",
    "        images.append(img)\n",
    "        labels.append(row['label_int'])\n",
    "        lotnames.append(row['lotName'])\n",
    "        original_indices.append(row['idx'])\n",
    "    \n",
    "    images = np.array(images, dtype=np.uint8)\n",
    "    labels = np.array(labels, dtype=np.uint8)\n",
    "    original_indices = np.array(original_indices, dtype=np.int32)\n",
    "    \n",
    "    # Save with gzip compression\n",
    "    h5_file.create_dataset(f\"{split_name}/images\", data=images, compression=\"gzip\", compression_opts=4)\n",
    "    h5_file.create_dataset(f\"{split_name}/labels\", data=labels, compression=\"gzip\")\n",
    "    h5_file.create_dataset(f\"{split_name}/lotnames\", data=np.array(lotnames, dtype='S'), compression=\"gzip\")\n",
    "    h5_file.create_dataset(f\"{split_name}/original_indices\", data=original_indices, compression=\"gzip\")\n",
    "    \n",
    "    print(f\"{split_name.upper()} saved: {images.shape} images, {images.nbytes / 1e9:.1f} GB\")\n",
    "\n",
    "print(\"Processing and saving to HDF5 (this will take 30-60 minutes)...\")\n",
    "with h5py.File(H5_PATH, 'w') as h5f:\n",
    "    save_split_to_h5(df_train, 'train', h5f)\n",
    "    save_split_to_h5(df_val, 'val', h5f)\n",
    "    save_split_to_h5(df_test, 'test', h5f)\n",
    "    \n",
    "    # Save class names and encoder\n",
    "    h5f.create_dataset('class_names', data=np.array(CLASSES, dtype='S'))\n",
    "    h5f.attrs['num_classes'] = len(CLASSES)\n",
    "\n",
    "print(f\"All done! HDF5 saved to: {H5_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7ef5a-b664-41d0-8af7-a1a78763b873",
   "metadata": {},
   "source": [
    "## EDA Plots (saved to figures/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79016c2d-4a89-4f3b-9415-f5304dc0bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='failureType', order=CLASSES)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Class Distribution (172k labeled samples)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"class_distribution.png\"), dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931c723-2280-4963-9a62-4f604b8b76f7",
   "metadata": {},
   "source": [
    "## Random 9 examples (one per class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a4b23ba-7a6f-4c13-b953-2c521b96c9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA figures saved to C:\\Users\\user\\Desktop\\project 465\\figures/\n",
      "\n",
      "=== DATA PIPELINE COMPLETE ===\n",
      "We can now instantly load data with:\n",
      "\n",
      "with h5py.File('dataset/processed/wm811k_processed_224.h5', 'r') as f:\n",
      "    X_train = f['train/images'][:]\n",
      "    y_train = f['train/labels'][:]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "axes = axes.ravel()\n",
    "for i, cls in enumerate(CLASSES):\n",
    "    sample = df[df['failureType'] == cls].sample(1, random_state=SEED)\n",
    "    raw_map = sample['waferMap'].values[0]\n",
    "    processed = preprocess_wafer(raw_map)[:, :, 0]  # show single channel\n",
    "    \n",
    "    axes[i].imshow(processed, cmap='gray')\n",
    "    axes[i].set_title(f\"{cls} (original shape: {raw_map.shape})\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(\"One Example Per Class (224×224 processed)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"examples_per_class.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Wafer original size distribution\n",
    "sizes = df['shape'].apply(lambda x: f\"{x[0]}×{x[1]}\")\n",
    "size_counts = Counter(sizes)\n",
    "common_sizes = size_counts.most_common(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(common_sizes)), [v for k,v in common_sizes])\n",
    "plt.xticks(range(len(common_sizes)), [k for k,v in common_sizes], rotation=45)\n",
    "plt.title('Top 10 Most Common Original Wafer Sizes')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, \"wafer_sizes.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"EDA figures saved to {FIGURES_DIR}/\")\n",
    "print(\"\\n=== DATA PIPELINE COMPLETE ===\")\n",
    "print(\"We can now instantly load data with:\")\n",
    "print(\"\"\"\n",
    "with h5py.File('dataset/processed/wm811k_processed_224.h5', 'r') as f:\n",
    "    X_train = f['train/images'][:]\n",
    "    y_train = f['train/labels'][:]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1794d66-caac-4225-b663-706024317b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
