{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8978f75d-dc9e-4443-b436-2c792176934d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692bece4-20d0-44c5-a80c-360864115ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import pandas as pd\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5776659-cd5e-4188-8c58-10f677464441",
   "metadata": {},
   "source": [
    "## Config Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0073570-e4a6-47b0-a9fa-8ddfee93135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, \"dataset\")\n",
    "PROCESSED_DIR = os.path.join(DATASET_DIR, \"processed\")\n",
    "FIGURES_DIR = os.path.join(ROOT_DIR, \"figures\")\n",
    "\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "PKL_PATH = os.path.join(DATASET_DIR, \"LSWMD.pkl\")\n",
    "H5_PATH = os.path.join(PROCESSED_DIR, \"wm811k_dual_224_final.h5\")  # chnaged name\n",
    "\n",
    "IMG_SIZE = 224  # changing the image resolution\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "CLASSES = ['none', 'Loc', 'Edge-Loc', 'Center', 'Edge-Ring', 'Scratch', 'Random', 'Donut', 'Near-full']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505d024-ff57-455a-bde3-3ee74b23d6e3",
   "metadata": {},
   "source": [
    "## Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb84034-000d-4228-982f-f1e792b120ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LSWMD.pkl...\n",
      "Total wafers in raw pickle: 811457\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 811457 entries, 0 to 811456\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   waferMap        811457 non-null  object \n",
      " 1   dieSize         811457 non-null  float64\n",
      " 2   lotName         811457 non-null  object \n",
      " 3   waferIndex      811457 non-null  float64\n",
      " 4   trianTestLabel  811457 non-null  object \n",
      " 5   failureType     811457 non-null  object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 37.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading LSWMD.pkl...\")\n",
    "data = pd.read_pickle(PKL_PATH)         \n",
    "\n",
    "print(f\"Total wafers in raw pickle: {len(data)}\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80acbc45-552c-4202-b429-979d70ae3db9",
   "metadata": {},
   "source": [
    "## Convert to DataFrame for easier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd97666-bad0-4f66-8c13-cec02833c671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully labeled samples: 172950\n",
      "\n",
      "Label distribution:\n",
      "failureType\n",
      "none         147431\n",
      "Edge-Ring      9680\n",
      "Edge-Loc       5189\n",
      "Center         4294\n",
      "Loc            3593\n",
      "Scratch        1193\n",
      "Random          866\n",
      "Donut           555\n",
      "Near-full       149\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Vectorized extraction\n",
    "def extract_label(ft):\n",
    "    if hasattr(ft, 'ndim') and ft.ndim == 2 and ft.size > 0:\n",
    "        val = ft[0][0]\n",
    "        if val not in ('', b''):\n",
    "            return str(val)      # force to Python str in case it's bytes\n",
    "    return np.nan\n",
    "\n",
    "# Apply the extraction\n",
    "data['failureType'] = data['failureType'].apply(extract_label)\n",
    "\n",
    "# Keep only the fully labeled ones\n",
    "df = data[data['failureType'].notna()].copy()\n",
    "\n",
    "# Add the extra columns you wanted\n",
    "df['shape'] = df['waferMap'].apply(lambda x: x.shape)\n",
    "df = df.reset_index().rename(columns={'index': 'idx'})   # 'idx' = original row number in the pickle\n",
    "\n",
    "print(f\"Fully labeled samples: {len(df)}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df['failureType'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff71eb-b539-4fc1-8f6d-b89f5ecd10f9",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2374328-b2f2-448c-b94b-1fab9ef63fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(CLASSES)\n",
    "df['label_int'] = le.transform(df['failureType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887da38-59f1-4357-a1b7-8f5597f0f638",
   "metadata": {},
   "source": [
    "## Lot-based train/val/test split (80/10/10) - NO LEAKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b37e3e22-8bf4-4e5c-8b73-b745a537301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=SEED)\n",
    "train_idx, temp_idx = next(gss.split(df, groups=df['lotName']))\n",
    "\n",
    "df_train = df.iloc[train_idx].copy()\n",
    "df_temp = df.iloc[temp_idx].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec3238-869a-4500-9143-6f2a4a6777ca",
   "metadata": {},
   "source": [
    "## Second split on remaining 20% → val/test 10/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9981c2e2-94e5-483d-a2b4-ec5cd0de5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 138503 | Val: 16834 | Test: 17613\n",
      "Unique lots - Train: 8609, Val: 1076, Test: 1077\n"
     ]
    }
   ],
   "source": [
    "gss2 = GroupShuffleSplit(n_splits=1, train_size=0.5, random_state=SEED+1)\n",
    "val_idx, test_idx = next(gss2.split(df_temp, groups=df_temp['lotName']))\n",
    "\n",
    "df_val = df_temp.iloc[val_idx].copy()\n",
    "df_test = df_temp.iloc[test_idx].copy()\n",
    "\n",
    "print(f\"Train: {len(df_train)} | Val: {len(df_val)} | Test: {len(df_test)}\")\n",
    "print(f\"Unique lots - Train: {df_train['lotName'].nunique()}, Val: {df_val['lotName'].nunique()}, Test: {df_test['lotName'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98cbe43-0699-4361-93d1-c76eaffd206c",
   "metadata": {},
   "source": [
    "## Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c52c95-b484-4d51-8203-5f989f38adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_wafer(wafer_map):\n",
    "#     \"\"\"\n",
    "#     Input: raw wafer_map (H, W) with values 0,1,2\n",
    "#     Output: (224,224,3) uint8 image ready for ImageNet-pretrained models\n",
    "#     \"\"\"\n",
    "#     # Convert to binary defect map: only defective dies = 255, everything else = 0\n",
    "#     defect = np.zeros(wafer_map.shape, dtype=np.uint8)\n",
    "#     defect[wafer_map == 2] = 255\n",
    "    \n",
    "#     # Resize with CUBIC (as requested, though NEAREST is also popular for binary)\n",
    "#     resized = cv2.resize(defect, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "#     # Convert to 3-channel\n",
    "#     resized_3ch = np.repeat(resized[:, :, np.newaxis], 3, axis=2)\n",
    "    \n",
    "#     return resized_3ch\n",
    "\n",
    "def preprocess_wafer(wafer_map):\n",
    "    \"\"\"\n",
    "    UPDATED FINAL VERSION\n",
    "    - Dual modality (raw + defect) for fusion training \n",
    "    - INTER_NEAREST only \n",
    "    - float32 + properly normalized \n",
    "    - Vectorized operations\n",
    "    - Returns tuple: (raw_3ch, defect_3ch) → both (224,224,3) float32\n",
    "    \"\"\"\n",
    "\n",
    "    # Vectorized + float32 (faster and correct for training) ===\n",
    "    # Raw map: keep 0,1,2 → normalize to [0.0, 0.5, 1.0]\n",
    "    raw = wafer_map.astype(np.float32) / 2.0\n",
    "    \n",
    "    # Defect mask: binary → 0.0 or 1.0 (no 255 uint8 nonsense)\n",
    "    defect = (wafer_map == 2).astype(np.float32)\n",
    "\n",
    "    # NEAREST only (preserves sharp edges & discrete values) ===\n",
    "    raw_resized = cv2.resize(raw, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "    defect_resized = cv2.resize(defect, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # 3-channel (ImageNet-pretrained expect 3ch) ===\n",
    "    raw_3ch = np.repeat(raw_resized[..., np.newaxis], 3, axis=-1)\n",
    "    defect_3ch = np.repeat(defect_resized[..., np.newaxis], 3, axis=-1)\n",
    "\n",
    "    # CHANGE 4: Return both (required for fusion - this is the only way to win) ===\n",
    "    return raw_3ch, defect_3ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38760a45-ad07-46f7-9000-02de7da1d459",
   "metadata": {},
   "source": [
    "## Process and save to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac1462e2-dc1c-4b53-8ec6-9b8746f0cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting final preprocessing and saving to HDF5...\n",
      "Processing train (138503 samples) → writing directly to disk (your style, no RAM crash)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████████████████████████████████████████████████████████████| 138503/138503 [08:08<00:00, 283.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN saved → 138503 samples (dual raw + defect)\n",
      "Processing val (16834 samples) → writing directly to disk (your style, no RAM crash)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|██████████████████████████████████████████████████████████████████████| 16834/16834 [00:58<00:00, 287.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL saved → 16834 samples (dual raw + defect)\n",
      "Processing test (17613 samples) → writing directly to disk (your style, no RAM crash)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|█████████████████████████████████████████████████████████████████████| 17613/17613 [01:01<00:00, 284.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST saved → 17613 samples (dual raw + defect)\n",
      "\n",
      "SUCCESS! Dual-input HDF5 ready at: C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\dataset\\processed\\wm811k_dual_224_final.h5\n"
     ]
    }
   ],
   "source": [
    "# def save_split_to_h5(df_split, split_name, h5_file):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     lotnames = []\n",
    "#     original_indices = []  # to trace back if needed\n",
    "    \n",
    "#     for _, row in df_split.iterrows():\n",
    "#         img = preprocess_wafer(row['waferMap'])\n",
    "#         images.append(img)\n",
    "#         labels.append(row['label_int'])\n",
    "#         lotnames.append(row['lotName'])\n",
    "#         original_indices.append(row['idx'])\n",
    "    \n",
    "#     images = np.array(images, dtype=np.uint8)\n",
    "#     labels = np.array(labels, dtype=np.uint8)\n",
    "#     original_indices = np.array(original_indices, dtype=np.int32)\n",
    "    \n",
    "#     # Save with gzip compression\n",
    "#     h5_file.create_dataset(f\"{split_name}/images\", data=images, compression=\"gzip\", compression_opts=4)\n",
    "#     h5_file.create_dataset(f\"{split_name}/labels\", data=labels, compression=\"gzip\")\n",
    "#     h5_file.create_dataset(f\"{split_name}/lotnames\", data=np.array(lotnames, dtype='S'), compression=\"gzip\")\n",
    "#     h5_file.create_dataset(f\"{split_name}/original_indices\", data=original_indices, compression=\"gzip\")\n",
    "    \n",
    "#     print(f\"{split_name.upper()} saved: {images.shape} images, {images.nbytes / 1e9:.1f} GB\")\n",
    "\n",
    "# print(\"Processing and saving to HDF5 (this will take 30-60 minutes)...\")\n",
    "# with h5py.File(H5_PATH, 'w') as h5f:\n",
    "#     save_split_to_h5(df_train, 'train', h5f)\n",
    "#     save_split_to_h5(df_val, 'val', h5f)\n",
    "#     save_split_to_h5(df_test, 'test', h5f)\n",
    "    \n",
    "#     # Save class names and encoder\n",
    "#     h5f.create_dataset('class_names', data=np.array(CLASSES, dtype='S'))\n",
    "#     h5f.attrs['num_classes'] = len(CLASSES)\n",
    "\n",
    "# print(f\"All done! HDF5 saved to: {H5_PATH}\")\n",
    "\n",
    "def save_split_to_h5(df_split, split_name, h5_file):\n",
    "    n = len(df_split)\n",
    "    \n",
    "    # Create datasets first (disk-backed)\n",
    "    raw_ds = h5_file.create_dataset(\n",
    "        f\"{split_name}/raw_images\", (n, IMG_SIZE, IMG_SIZE, 3),\n",
    "        dtype=np.float32, compression=\"gzip\", compression_opts=4, chunks=(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    defect_ds = h5_file.create_dataset(\n",
    "        f\"{split_name}/defect_images\", (n, IMG_SIZE, IMG_SIZE, 3),\n",
    "        dtype=np.float32, compression=\"gzip\", compression_opts=4, chunks=(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    label_ds = h5_file.create_dataset(f\"{split_name}/labels\", (n,), dtype=np.int64, compression=\"gzip\")\n",
    "    lotname_ds = h5_file.create_dataset(f\"{split_name}/lotnames\", (n,), dtype=h5py.string_dtype(), compression=\"gzip\")\n",
    "    idx_ds = h5_file.create_dataset(f\"{split_name}/original_indices\", (n,), dtype=np.int32, compression=\"gzip\")\n",
    "\n",
    "    print(f\"Processing {split_name} ({n} samples)\")\n",
    "\n",
    "    for i, (_, row) in enumerate(tqdm(df_split.iterrows(), total=n, desc=split_name)):\n",
    "        raw_img, defect_img = preprocess_wafer(row['waferMap'])\n",
    "        \n",
    "        raw_ds[i] = raw_img\n",
    "        defect_ds[i] = defect_img\n",
    "        label_ds[i] = row['label_int']\n",
    "        lotname_ds[i] = str(row['lotName'])\n",
    "        idx_ds[i] = row['idx']\n",
    "\n",
    "    print(f\"{split_name.upper()} saved → {n} samples (dual raw + defect)\")\n",
    "\n",
    "# === CALL BLOCK ===\n",
    "print(\"Starting final preprocessing and saving to HDF5...\")\n",
    "with h5py.File(H5_PATH, 'w') as h5f:\n",
    "    save_split_to_h5(df_train, 'train', h5f)\n",
    "    save_split_to_h5(df_val,   'val',   h5f)\n",
    "    save_split_to_h5(df_test,  'test',  h5f)\n",
    "\n",
    "    h5f.create_dataset('class_names', data=np.array(CLASSES, dtype='S'))\n",
    "    h5f.attrs['num_classes'] = len(CLASSES)\n",
    "    h5f.attrs['label_encoder_classes'] = np.array(le.classes_, dtype='S')\n",
    "\n",
    "    h5f.create_dataset(\"splits/train_idx\", data=np.array(train_idx, dtype=np.int32), compression=\"gzip\")\n",
    "    h5f.create_dataset(\"splits/val_idx\",   data=np.array(val_idx,   dtype=np.int32), compression=\"gzip\")\n",
    "    h5f.create_dataset(\"splits/test_idx\",  data=np.array(test_idx,  dtype=np.int32), compression=\"gzip\")\n",
    "\n",
    "print(f\"\\nSUCCESS! Dual-input HDF5 ready at: {H5_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7ef5a-b664-41d0-8af7-a1a78763b873",
   "metadata": {},
   "source": [
    "## EDA Plots (saved to figures/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79016c2d-4a89-4f3b-9415-f5304dc0bad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dual class examples (this takes ~30 seconds)...\n",
      "Dualnvisualization saved: C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\figures\\dual_channel_class_examples.png\n"
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.countplot(data=df, x='failureType', order=CLASSES)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.title('Class Distribution (172k labeled samples)')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(FIGURES_DIR, \"class_distribution.png\"), dpi=300)\n",
    "# plt.close()\n",
    "\n",
    "# === CONFIG ===\n",
    "n_examples_per_class = 5\n",
    "fig, axes = plt.subplots(9, 2, figsize=(10, 36))  # 9 classes × (raw | defect)\n",
    "axes = axes.ravel()\n",
    "\n",
    "print(\"Generating dual class examples (this takes ~30 seconds)...\")\n",
    "\n",
    "idx = 0\n",
    "for class_name in CLASSES:\n",
    "    # Get random samples for this class\n",
    "    samples = df[df['failureType'] == class_name].sample(n=n_examples_per_class, random_state=42)\n",
    "    \n",
    "    # We'll show only the first sample as title, rest as small thumbnails below\n",
    "    first_row = samples.iloc[0]\n",
    "    raw_map = first_row['waferMap']\n",
    "    \n",
    "    # Process once\n",
    "    raw_img, defect_img = preprocess_wafer(raw_map)\n",
    "    \n",
    "    # === RAW MAP (left column) ===\n",
    "    axes[idx].imshow(raw_img[:, :, 0], cmap='viridis')  # viridis = exactly like 2015 paper Fig.2(a)\n",
    "    axes[idx].set_title(f\"{class_name} — Raw Wafer Map (0,1,2)\", fontsize=14, weight='bold')\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # === DEFECT MASK (right column) ===\n",
    "    axes[idx + 1].imshow(defect_img[:, :, 0], cmap='gray')\n",
    "    axes[idx + 1].set_title(f\"{class_name} — Defect Mask (binary)\", fontsize=14, weight='bold')\n",
    "    axes[idx + 1].axis('off')\n",
    "    \n",
    "    idx += 2\n",
    "\n",
    "plt.suptitle('WM-811K Dataset: Dual Visualization\\n'\n",
    "             'Left: Raw Map (0=background, 1=normal die, 2=defect) | Right: Binary Defect Mask\\n'\n",
    "             '224×224, NEAREST interpolation, float32 normalized',\n",
    "             fontsize=18, weight='bold', y=0.98)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "save_path = os.path.join(FIGURES_DIR, \"dual_channel_class_examples.png\")\n",
    "plt.savefig(save_path, dpi=400, bbox_inches='tight', facecolor='white')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Dualnvisualization saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931c723-2280-4963-9a62-4f604b8b76f7",
   "metadata": {},
   "source": [
    "## Class examples in 3x6 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a4b23ba-7a6f-4c13-b953-2c521b96c9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dual-channel 3×6 example grid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13672\\475822562.py:55: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual-channel 3×6 example grid saved: C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\figures\\dual_channel_examples_3x6.png\n"
     ]
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Create 3×6 grid: 3 rows, 6 columns → 9 classes × (Raw | Defect)\n",
    "fig, axes = plt.subplots(3, 6, figsize=(18, 9))\n",
    "fig.suptitle(\"One Example Per Class — Dual-Channel View (224×224, NEAREST)\\n\"\n",
    "             \"Left: Raw Wafer Map (0=background, 1=normal die, 2=defect) | Right: Binary Defect Mask\",\n",
    "             fontsize=18, weight='bold', y=0.98)\n",
    "\n",
    "print(\"Generating dual-channel 3×6 example grid...\")\n",
    "\n",
    "for idx, cls in enumerate(CLASSES):\n",
    "    row = idx // 3\n",
    "    col_raw = (idx % 3) * 2        # Left column: raw map\n",
    "    col_defect = col_raw + 1      # Right column: defect mask\n",
    "    \n",
    "    # Sample one wafer from this class\n",
    "    sample = df[df['failureType'] == cls].sample(1, random_state=SEED + idx)\n",
    "    raw_map = sample['waferMap'].values[0]\n",
    "    orig_shape = raw_map.shape\n",
    "    \n",
    "    # Preprocess → dual output\n",
    "    raw_img, defect_img = preprocess_wafer(raw_map)\n",
    "    \n",
    "    # === Plot Raw Map  ===\n",
    "    im1 = axes[row, col_raw].imshow(raw_img[:, :, 0], cmap='viridis', vmin=0, vmax=1)\n",
    "    axes[row, col_raw].set_title(f\"{cls}\\nRaw Map\", fontsize=13, weight='bold')\n",
    "    axes[row, col_raw].axis('off')\n",
    "    \n",
    "    # === Plot Defect Mask  ===\n",
    "    im2 = axes[row, col_defect].imshow(defect_img[:, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    axes[row, col_defect].set_title(f\"{cls}\\nDefect Mask\", fontsize=13, weight='bold')\n",
    "    axes[row, col_defect].axis('off')\n",
    "    \n",
    "    # Add original size as subtitle\n",
    "    axes[row, col_raw].text(0.5, -0.1, f\"orig: {orig_shape}\", \n",
    "                            transform=axes[row, col_raw].transAxes, \n",
    "                            ha='center', fontsize=10, style='italic')\n",
    "\n",
    "# === Colorbars (optional — looks very professional) ===\n",
    "plt.colorbar(im1, ax=axes[:, :3].ravel().tolist(), fraction=0.02, pad=0.04, label='Normalized Intensity (0.0–1.0)')\n",
    "cb = plt.colorbar(im2, ax=axes[:, 3:].ravel().tolist(),\n",
    "                  fraction=0.02, pad=0.04, label='Defect Presence')\n",
    "\n",
    "# Shift colorbar position to the left by modifying the bounding box\n",
    "pos = cb.ax.get_position()\n",
    "cb.ax.set_position([\n",
    "    pos.x0 - 0.04,   # shift left \n",
    "    pos.y0,\n",
    "    pos.width,\n",
    "    pos.height\n",
    "])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "save_path = os.path.join(FIGURES_DIR, \"dual_channel_examples_3x6.png\")\n",
    "plt.savefig(save_path, dpi=400, bbox_inches='tight', facecolor='white')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Dual-channel 3×6 example grid saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86542c-060f-4b05-98ff-80e10db4ba47",
   "metadata": {},
   "source": [
    "## Class distribution and wafer size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1794d66-caac-4225-b663-706024317b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13672\\2507747336.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.countplot(data=df, x='failureType', order=CLASSES, palette=\"deep\", edgecolor=\"black\", linewidth=1.2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED & DISPLAYED: C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\figures\\class_distribution.png\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED & DISPLAYED: C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\figures\\wafer_size_distribution.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "if 'shape' not in df.columns:\n",
    "    print(\"'shape' column missing → adding it now...\")\n",
    "    df['shape'] = df['waferMap'].apply(lambda x: x.shape)\n",
    "\n",
    "# =================================================\n",
    "# Class Distribution \n",
    "# =================================================\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = sns.countplot(data=df, x='failureType', order=CLASSES, palette=\"deep\", edgecolor=\"black\", linewidth=1.2)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Failure Pattern Type', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Number of Samples', fontsize=14, labelpad=10)\n",
    "plt.title('WM-811K Dataset: Class Distribution (172,251 Labeled Samples)', \n",
    "          fontsize=16, weight='bold', pad=20)\n",
    "\n",
    "# FIXED: Dynamic label positioning to avoid overlap\n",
    "max_count = df['failureType'].value_counts().max()\n",
    "offset = max_count * 0.02  # 2% of max height\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.annotate(f'{int(height)}', \n",
    "                (p.get_x() + p.get_width()/2., height + offset),\n",
    "                ha='center', va='bottom', fontsize=11, weight='medium')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "class_dist_path = os.path.join(FIGURES_DIR, \"class_distribution.png\")\n",
    "plt.savefig(class_dist_path, dpi=500, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "print(f\"SAVED & DISPLAYED: {class_dist_path}\\n\")\n",
    "\n",
    "# =================================================\n",
    "# Wafer Size Distribution \n",
    "# =================================================\n",
    "sizes = df['shape'].apply(lambda x: f\"{x[0]}×{x[1]}\")\n",
    "top10 = Counter(sizes).most_common(10)\n",
    "\n",
    "plt.figure(figsize=(11, 7))\n",
    "bars = plt.bar(range(len(top10)), [v for _, v in top10], \n",
    "               color='#1f77b4', edgecolor='black', linewidth=1.2)\n",
    "plt.xticks(range(len(top10)), [k for k, _ in top10], rotation=45, ha='right', fontsize=11)\n",
    "plt.xlabel('Original Wafer Map Resolution', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Number of Samples', fontsize=14, labelpad=10)\n",
    "plt.title('Top 10 Most Common Wafer Resolutions in WM-811K', \n",
    "          fontsize=16, weight='bold', pad=20)\n",
    "\n",
    "# FIXED: Dynamic offset based on max value\n",
    "max_val = max([v for _, v in top10])\n",
    "offset = max_val * 0.03  # 3% above bar\n",
    "\n",
    "for bar in bars:\n",
    "    h = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., h + offset, f'{int(h)}', \n",
    "             ha='center', va='bottom', fontsize=11, weight='medium')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "size_path = os.path.join(FIGURES_DIR, \"wafer_size_distribution.png\")\n",
    "plt.savefig(size_path, dpi=500, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"SAVED & DISPLAYED: {size_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27099dc3-7db4-430b-8f93-8874335bf0a0",
   "metadata": {},
   "source": [
    "# Training starts\n",
    "\n",
    "install the following libararies in the system:<br>\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118<br>\n",
    "pip install timm h5py wandb tqdm seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c212ae-ded6-4d64-9a23-a0b23e6ee9ba",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704241ae-1191-43c3-ba5a-997cb83da5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb7ad7-5df5-44b1-972c-94e2fb09705b",
   "metadata": {},
   "source": [
    "# Testing data from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6170934a-903c-4b5c-af7f-588e4a5cbbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! One sample loaded\n",
      "Raw shape: torch.Size([3, 224, 224]) Defect shape: torch.Size([3, 224, 224])\n",
      "Label: 8 → Class: Near-full\n"
     ]
    }
   ],
   "source": [
    "H5_PATH = \"dataset/processed/wm811k_dual_224_final.h5\"\n",
    "class WM811KDataset(Dataset):\n",
    "    def __init__(self, split='train'):  # split = 'train', 'val', or 'test'\n",
    "        self.h5 = h5py.File(H5_PATH, 'r')\n",
    "        self.raw = self.h5[f'{split}/raw_images']\n",
    "        self.defect = self.h5[f'{split}/defect_images']\n",
    "        self.labels = self.h5[f'{split}/labels']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raw = torch.tensor(self.raw[idx]).permute(2, 0, 1)  # (3, 224, 224)\n",
    "        defect = torch.tensor(self.defect[idx]).permute(2, 0, 1)  # (3, 224, 224)\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return raw, defect, label\n",
    "    \n",
    "    def close(self):\n",
    "        if hasattr(self, 'h5'):\n",
    "            self.h5.close()\n",
    "\n",
    "# Quick test\n",
    "if __name__ == \"__main__\":\n",
    "    train_ds = WM811KDataset('train')\n",
    "    raw, defect, label = train_ds[0]\n",
    "    print(\"Success! One sample loaded\")\n",
    "    print(\"Raw shape:\", raw.shape, \"Defect shape:\", defect.shape)\n",
    "    print(\"Label:\", label.item(), \"→ Class:\", train_ds.h5['class_names'][label.item()].decode())\n",
    "    train_ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ed47a-add6-49a1-ae63-c2c9d3385bab",
   "metadata": {},
   "source": [
    "# Data Loader test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b8cd54-6c5a-4129-8f39-3b4d65405a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader success!\n",
      "Batch raw shape: torch.Size([4, 3, 224, 224])\n",
      "Batch defect shape: torch.Size([4, 3, 224, 224])\n",
      "Batch labels: [8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloaders(batch_size=32):\n",
    "    train_ds = WM811KDataset('train')\n",
    "    val_ds = WM811KDataset('val')\n",
    "    test_ds = WM811KDataset('test')\n",
    "    \n",
    "    # Windows fix: no multiprocessing → num_workers=0\n",
    "    workers = 0 if os.name == 'nt' else os.cpu_count()\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=workers, pin_memory=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=batch_size*2, shuffle=False, \n",
    "                        num_workers=workers, pin_memory=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size*2, shuffle=False, \n",
    "                         num_workers=workers, pin_memory=True)\n",
    "    \n",
    "    return train_dl, val_dl, test_dl\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    train_dl, _, _ = get_dataloaders(batch_size=4)\n",
    "    batch = next(iter(train_dl))\n",
    "    raw, defect, labels = batch\n",
    "    print(\"DataLoader success!\")\n",
    "    print(\"Batch raw shape:\", raw.shape)      # [4, 224, 224, 3]\n",
    "    print(\"Batch defect shape:\", defect.shape)\n",
    "    print(\"Batch labels:\", labels.tolist())\n",
    "    \n",
    "    # Close datasets to free memory\n",
    "    train_dl.dataset.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8cded-5deb-418a-899e-737c3701e24c",
   "metadata": {},
   "source": [
    "# Test gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5f5b3c-6036-4b9c-99d9-44ab4b827fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "True\n",
      "NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff2cf0",
   "metadata": {},
   "source": [
    "## Path for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce05f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e6146",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f9524-79d1-4b59-9ddf-bb98c3b5d4f0",
   "metadata": {},
   "source": [
    "# ResNet50 (baseline 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e08b8061-f0f4-401b-a69f-e4317320ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f78d5202de4a4bb0aff4f543b84e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: asifakbarzishan14 (asifakbarzishan14-north-south-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\wandb\\run-20251208_154309-y9w5frhe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/y9w5frhe' target=\"_blank\">wandering-tree-1</a></strong> to <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/y9w5frhe' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/y9w5frhe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:09<00:00,  7.87it/s]\n",
      "Epoch 1/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.1062 | Val Loss 0.0439 | Val Acc 0.9680 | Val F1 0.7346\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:02<00:00,  7.98it/s]\n",
      "Epoch 2/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.0324 | Val Loss 0.0391 | Val Acc 0.9699 | Val F1 0.8446\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:07<00:00,  7.91it/s]\n",
      "Epoch 3/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.0223 | Val Loss 0.0343 | Val Acc 0.9716 | Val F1 0.7724\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:03<00:00,  7.96it/s]\n",
      "Epoch 4/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.0151 | Val Loss 0.0362 | Val Acc 0.9705 | Val F1 0.7892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:04<00:00,  7.96it/s]\n",
      "Epoch 5/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [02:56<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.0101 | Val Loss 0.0420 | Val Acc 0.9720 | Val F1 0.7697\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:05<00:00,  7.94it/s]\n",
      "Epoch 6/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.0060 | Val Loss 0.0460 | Val Acc 0.9736 | Val F1 0.7642\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:16<00:00,  7.78it/s]\n",
      "Epoch 7/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:42<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.0040 | Val Loss 0.0421 | Val Acc 0.9743 | Val F1 0.7875\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:05<00:00,  7.93it/s]\n",
      "Epoch 8/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.0027 | Val Loss 0.0382 | Val Acc 0.9765 | Val F1 0.8825\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:04<00:00,  7.95it/s]\n",
      "Epoch 9/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.0017 | Val Loss 0.0449 | Val Acc 0.9742 | Val F1 0.7854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:31<00:00,  7.57it/s]\n",
      "Epoch 10/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0012 | Val Loss 0.0455 | Val Acc 0.9755 | Val F1 0.7946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:05<00:00,  7.94it/s]\n",
      "Epoch 11/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.0006 | Val Loss 0.0560 | Val Acc 0.9755 | Val F1 0.8252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:05<00:00,  7.94it/s]\n",
      "Epoch 12/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.0004 | Val Loss 0.0504 | Val Acc 0.9753 | Val F1 0.8057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:05<00:00,  7.94it/s]\n",
      "Epoch 13/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.0002 | Val Loss 0.0517 | Val Acc 0.9755 | Val F1 0.8401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:04<00:00,  7.95it/s]\n",
      "Epoch 14/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.0002 | Val Loss 0.0507 | Val Acc 0.9759 | Val F1 0.8325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:05<00:00,  7.94it/s]\n",
      "Epoch 15/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.0001 | Val Loss 0.0524 | Val Acc 0.9758 | Val F1 0.8307\n",
      "Training done! Check WandB for graphs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "import timm  # For pretrained models\n",
    "from tqdm import tqdm  # Progress bars\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Focal Loss for imbalance\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # Can be None or a tensor of shape [9]\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()\n",
    "\n",
    "# Dual-Input Model (concat raw + defect → 6 channels)\n",
    "class DualResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        # Load ResNet50, change in_channels to 6\n",
    "        self.backbone = timm.create_model('resnet50', pretrained=True, num_classes=num_classes)\n",
    "        self.backbone.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 6ch input\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        x = torch.cat([raw, defect], dim=1)  # (B,3,224,224) + (B,3,224,224) → (B,6,224,224)\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Training function\n",
    "def train_model(epochs=50, batch_size=32, lr=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    # Model, Loss, Optimizer\n",
    "    model = DualResNet50(num_classes=9).to(device)\n",
    "    criterion = FocalLoss(gamma=2.0).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # WandB init\n",
    "    wandb.init(project=\"wm811k-baseline\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        # Log to WandB\n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss, \n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        # Early stop / save best\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/resnet50_dual_best.pth\")\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    # Close datasets\n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"Training done! Check WandB for graphs.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(epochs=15, batch_size=32, lr=1e-4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbadb4c7-c2f8-4aa6-b820-f6a5036c2b7c",
   "metadata": {},
   "source": [
    "## ResNet50 (with class weights) (baseline 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c60c015a-80dc-4aa7-8581-753748e55646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>███▇▇▆▆▅▄▃▃▂▂▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▃▄▆▆█▆▇▇▇▇█▇</td></tr><tr><td>val_loss</td><td>▄▃▁▂▃▅▄▂▄▅█▆▇▆▇</td></tr><tr><td>val_macro_f1</td><td>▁▆▃▄▃▂▄█▃▄▅▄▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.00012</td></tr><tr><td>val_acc</td><td>0.97576</td></tr><tr><td>val_loss</td><td>0.05239</td></tr><tr><td>val_macro_f1</td><td>0.83069</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-tree-1</strong> at: <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/y9w5frhe' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/y9w5frhe</a><br> View project at: <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251208_154309-y9w5frhe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\wandb\\run-20251208_181609-3x9orrph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/3x9orrph' target=\"_blank\">copper-donkey-2</a></strong> to <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/3x9orrph' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/3x9orrph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:09<00:00,  7.88it/s]\n",
      "Epoch 1/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.1152 | Val Loss 0.0292 | Val Acc 0.9156 | Val F1 0.5057\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:12<00:00,  7.84it/s]\n",
      "Epoch 2/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:42<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.0214 | Val Loss 0.0193 | Val Acc 0.9363 | Val F1 0.5724\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:07<00:00,  7.91it/s]\n",
      "Epoch 3/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.0135 | Val Loss 0.0159 | Val Acc 0.9494 | Val F1 0.6699\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:06<00:00,  7.92it/s]\n",
      "Epoch 4/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.0101 | Val Loss 0.0273 | Val Acc 0.9459 | Val F1 0.6419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:06<00:00,  7.93it/s]\n",
      "Epoch 5/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:42<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.0075 | Val Loss 0.0143 | Val Acc 0.9587 | Val F1 0.7839\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:05<00:00,  7.94it/s]\n",
      "Epoch 6/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.0057 | Val Loss 0.0164 | Val Acc 0.9619 | Val F1 0.7354\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:04<00:00,  7.95it/s]\n",
      "Epoch 7/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.0046 | Val Loss 0.0142 | Val Acc 0.9676 | Val F1 0.8431\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:03<00:00,  7.97it/s]\n",
      "Epoch 8/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.0030 | Val Loss 0.0150 | Val Acc 0.9693 | Val F1 0.8375\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [09:04<00:00,  7.95it/s]\n",
      "Epoch 9/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.0022 | Val Loss 0.0208 | Val Acc 0.9707 | Val F1 0.8234\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:04<00:00,  7.95it/s]\n",
      "Epoch 10/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0016 | Val Loss 0.0252 | Val Acc 0.9721 | Val F1 0.8192\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:02<00:00,  7.98it/s]\n",
      "Epoch 11/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.0009 | Val Loss 0.0272 | Val Acc 0.9723 | Val F1 0.7978\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:02<00:00,  7.98it/s]\n",
      "Epoch 12/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.0006 | Val Loss 0.0283 | Val Acc 0.9731 | Val F1 0.8143\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:03<00:00,  7.97it/s]\n",
      "Epoch 13/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:40<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.0004 | Val Loss 0.0301 | Val Acc 0.9743 | Val F1 0.8103\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:02<00:00,  7.97it/s]\n",
      "Epoch 14/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.0003 | Val Loss 0.0325 | Val Acc 0.9746 | Val F1 0.8460\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [09:02<00:00,  7.98it/s]\n",
      "Epoch 15/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:41<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.0003 | Val Loss 0.0277 | Val Acc 0.9744 | Val F1 0.8652\n",
      "Training done! Check WandB for graphs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "import timm  # For pretrained models\n",
    "from tqdm import tqdm  # Progress bars\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Class weights for Focal Loss (from your dataset distribution)\n",
    "CLASS_COUNTS = [147431, 3593, 5189, 4294, 9680, 1193, 866, 555, 149]  # none, Loc, Edge-Loc, Center, Edge-Ring, Scratch, Random, Donut, Near-full\n",
    "CLASS_WEIGHTS = torch.tensor(CLASS_COUNTS, dtype=torch.float32)\n",
    "CLASS_WEIGHTS = CLASS_WEIGHTS.sum() / (9 * CLASS_WEIGHTS)\n",
    "CLASS_WEIGHTS = CLASS_WEIGHTS / CLASS_WEIGHTS.sum() * 9   # Normalized inverse frequencies\n",
    "\n",
    "# Focal Loss for imbalance (now with weights)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=CLASS_WEIGHTS, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha.to('cuda' if torch.cuda.is_available() else 'cpu') if alpha is not None else None\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()\n",
    "\n",
    "# Dual-Input Model (concat raw + defect → 6 channels)\n",
    "class DualResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        # Load ResNet50, change in_channels to 6\n",
    "        self.backbone = timm.create_model('resnet50', pretrained=True, num_classes=num_classes)\n",
    "        self.backbone.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 6ch input\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        x = torch.cat([raw, defect], dim=1)  # (B,3,224,224) + (B,3,224,224) → (B,6,224,224)\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Training function\n",
    "def train_model(epochs=50, batch_size=32, lr=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    # Model, Loss, Optimizer\n",
    "    model = DualResNet50(num_classes=9).to(device)\n",
    "    criterion = FocalLoss(gamma=2.0).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # WandB init\n",
    "    wandb.init(project=\"wm811k-baseline\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        # Log to WandB\n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        # Early stop / save best\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/resnet50_dual_best_with_weight_class.pth\")\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    # Close datasets\n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"Training done! Check WandB for graphs.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model(epochs=15, batch_size=32, lr=1e-4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da0cd9",
   "metadata": {},
   "source": [
    "## We can see without weight class it performs better with better accuracy and f1 score. So we will be using no weight class for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737b7b6",
   "metadata": {},
   "source": [
    "# Training other baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c265a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "import timm  # For pretrained models\n",
    "from tqdm import tqdm  # Progress bars\n",
    "import wandb\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ccdacc",
   "metadata": {},
   "source": [
    "## CovNeXt (Baseline 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5946158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e338da8feb004d649190f70d71971879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: asifakbarzishan14 (asifakbarzishan14-north-south-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\wandb\\run-20251210_133546-yq7xe19s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yq7xe19s' target=\"_blank\">breezy-plasma-3</a></strong> to <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yq7xe19s' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yq7xe19s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [24:28<00:00,  2.95it/s]\n",
      "Epoch 1/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.0498 | Val Loss 0.0328 | Val Acc 0.9726 | Val F1 0.8290\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [23:54<00:00,  3.02it/s]\n",
      "Epoch 2/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.0263 | Val Loss 0.0314 | Val Acc 0.9748 | Val F1 0.8040\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [23:54<00:00,  3.02it/s]\n",
      "Epoch 3/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.0191 | Val Loss 0.0274 | Val Acc 0.9760 | Val F1 0.8212\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [23:54<00:00,  3.02it/s]\n",
      "Epoch 4/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.0136 | Val Loss 0.0280 | Val Acc 0.9736 | Val F1 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [23:54<00:00,  3.02it/s]\n",
      "Epoch 5/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.0089 | Val Loss 0.0339 | Val Acc 0.9721 | Val F1 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [23:55<00:00,  3.02it/s]\n",
      "Epoch 6/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.0051 | Val Loss 0.0391 | Val Acc 0.9775 | Val F1 0.8882\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [24:02<00:00,  3.00it/s]\n",
      "Epoch 7/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:02<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.0032 | Val Loss 0.0412 | Val Acc 0.9782 | Val F1 0.9015\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [23:58<00:00,  3.01it/s]\n",
      "Epoch 8/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:02<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.0021 | Val Loss 0.0478 | Val Acc 0.9788 | Val F1 0.9031\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [23:58<00:00,  3.01it/s]\n",
      "Epoch 9/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.0012 | Val Loss 0.0464 | Val Acc 0.9785 | Val F1 0.8798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [23:53<00:00,  3.02it/s]\n",
      "Epoch 10/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0007 | Val Loss 0.0463 | Val Acc 0.9797 | Val F1 0.9131\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [23:53<00:00,  3.02it/s]\n",
      "Epoch 11/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.0004 | Val Loss 0.0627 | Val Acc 0.9783 | Val F1 0.9035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [23:52<00:00,  3.02it/s]\n",
      "Epoch 12/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.0002 | Val Loss 0.0623 | Val Acc 0.9801 | Val F1 0.9072\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [23:53<00:00,  3.02it/s]\n",
      "Epoch 13/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.0001 | Val Loss 0.0563 | Val Acc 0.9806 | Val F1 0.9158\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [23:52<00:00,  3.02it/s]\n",
      "Epoch 14/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.0001 | Val Loss 0.0585 | Val Acc 0.9808 | Val F1 0.9185\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [23:52<00:00,  3.02it/s]\n",
      "Epoch 15/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.0000 | Val Loss 0.0595 | Val Acc 0.9811 | Val F1 0.9144\n",
      "Saved best model!\n",
      "Baseline 2 done! Check WandB.\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # None for no weights\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()\n",
    "\n",
    "# Baseline 2 Model: DualConvNeXtBase (concat to 6 channels)\n",
    "class DualConvNeXtBase(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=True, num_classes=num_classes)\n",
    "        self.backbone.stem[0] = nn.Conv2d(6, 128, kernel_size=4, stride=4)  # 6 channels input\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        x = torch.cat([raw, defect], dim=1)  # (B, 6, 224, 224)\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Training function for Baseline 2 (uses your get_dataloaders)\n",
    "def train_baseline2(epochs=15, batch_size=32, lr=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    model = DualConvNeXtBase(num_classes=9).to(device)\n",
    "    criterion = FocalLoss(gamma=2.0).to(device)  # Without weights\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # Optional use. I will use it if memory goes out (Mixed precision)\n",
    "    # from torch.cuda.amp import autocast, GradScaler\n",
    "    # scaler = GradScaler()\n",
    "    \n",
    "    wandb.init(project=\"wm811k-baseline\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"model\": \"ConvNeXt-Base\"})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # with autocast():  # for mixed precision\n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scaler.scale(loss).backward()  # for mixed precision\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/convnext_base_best.pth\")  # Saves to models/ dir\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"Baseline 2 done! Check WandB.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_baseline2(epochs=15, batch_size=32, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8f35a",
   "metadata": {},
   "source": [
    "## Swinebase (baseline 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f317859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5228f8637c744642b10b224f8dbfe8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>███▇▇▆▆▅▄▃▃▂▂▁▁</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▂▁▅▆▆▆▇▆▇███</td></tr><tr><td>val_loss</td><td>▂▂▁▁▂▃▄▅▅▅██▇▇▇</td></tr><tr><td>val_macro_f1</td><td>▃▁▂▆▇▆▇▇▆█▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>4e-05</td></tr><tr><td>val_acc</td><td>0.98105</td></tr><tr><td>val_loss</td><td>0.05951</td></tr><tr><td>val_macro_f1</td><td>0.91442</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-plasma-3</strong> at: <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yq7xe19s' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yq7xe19s</a><br> View project at: <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251210_133546-yq7xe19s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\wandb\\run-20251210_195308-yabn4zwj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yabn4zwj' target=\"_blank\">fresh-fire-4</a></strong> to <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yabn4zwj' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yabn4zwj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:31<00:00,  3.52it/s]\n",
      "Epoch 1/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:10<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.0978 | Val Loss 0.0533 | Val Acc 0.9612 | Val F1 0.7568\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:32<00:00,  3.51it/s]\n",
      "Epoch 2/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:10<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.0380 | Val Loss 0.0382 | Val Acc 0.9730 | Val F1 0.8155\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:32<00:00,  3.51it/s]\n",
      "Epoch 3/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:10<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.0299 | Val Loss 0.0383 | Val Acc 0.9714 | Val F1 0.8211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:39<00:00,  3.49it/s]\n",
      "Epoch 4/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:11<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.0236 | Val Loss 0.0414 | Val Acc 0.9705 | Val F1 0.8246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:44<00:00,  3.48it/s]\n",
      "Epoch 5/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:11<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.0192 | Val Loss 0.0364 | Val Acc 0.9709 | Val F1 0.8579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:39<00:00,  3.49it/s]\n",
      "Epoch 6/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:10<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.0149 | Val Loss 0.0349 | Val Acc 0.9727 | Val F1 0.8698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:30<00:00,  3.52it/s]\n",
      "Epoch 7/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:10<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.0111 | Val Loss 0.0376 | Val Acc 0.9742 | Val F1 0.8415\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:31<00:00,  3.52it/s]\n",
      "Epoch 8/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:10<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.0074 | Val Loss 0.0366 | Val Acc 0.9772 | Val F1 0.8748\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [20:31<00:00,  3.52it/s]\n",
      "Epoch 9/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:10<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.0048 | Val Loss 0.0422 | Val Acc 0.9717 | Val F1 0.8542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [20:43<00:00,  3.48it/s]\n",
      "Epoch 10/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:12<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0031 | Val Loss 0.0446 | Val Acc 0.9786 | Val F1 0.8742\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [20:43<00:00,  3.48it/s]\n",
      "Epoch 11/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:11<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.0017 | Val Loss 0.0547 | Val Acc 0.9783 | Val F1 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [20:43<00:00,  3.48it/s]\n",
      "Epoch 12/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:11<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.0010 | Val Loss 0.0557 | Val Acc 0.9772 | Val F1 0.8886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [20:42<00:00,  3.49it/s]\n",
      "Epoch 13/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:11<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.0006 | Val Loss 0.0544 | Val Acc 0.9806 | Val F1 0.9097\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [20:45<00:00,  3.47it/s]\n",
      "Epoch 14/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:11<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.0003 | Val Loss 0.0542 | Val Acc 0.9781 | Val F1 0.8973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [21:19<00:00,  3.38it/s]\n",
      "Epoch 15/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:12<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.0003 | Val Loss 0.0556 | Val Acc 0.9791 | Val F1 0.8974\n",
      "Baseline 3 done! Check WandB.\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # None for no weights\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()\n",
    "\n",
    "# Baseline 3 Model: DualSwinBase (concat to 6 channels)\n",
    "class DualSwinBase(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=True, num_classes=num_classes)\n",
    "        self.backbone.patch_embed.proj = nn.Conv2d(6, 128, kernel_size=4, stride=4)  # 6 channels input\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        x = torch.cat([raw, defect], dim=1)  # (B, 6, 224, 224)\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Training function for Baseline 3 (uses your get_dataloaders)\n",
    "def train_baseline3(epochs=15, batch_size=32, lr=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    model = DualSwinBase(num_classes=9).to(device)\n",
    "    criterion = FocalLoss(gamma=2.0).to(device)  # Without weights\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # Optional use.\n",
    "    # from torch.cuda.amp import autocast, GradScaler\n",
    "    # scaler = GradScaler()\n",
    "    \n",
    "    wandb.init(project=\"wm811k-baseline\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"model\": \"Swin-Base\"})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # with autocast():  # for mixed precision\n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scaler.scale(loss).backward()  # for mixed precision\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/swin_base_best.pth\")  # Saves to models/ dir\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"Baseline 3 done! Check WandB.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  train_baseline3(epochs=15, batch_size=32, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752bade2",
   "metadata": {},
   "source": [
    "## ViTbase (baseline 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7fa01bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9539302797466a926beee63b281cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>███▇▇▆▆▅▄▃▃▂▂▁▁</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▅▄▅▅▆▇▅▇▇▇█▇▇</td></tr><tr><td>val_loss</td><td>▇▂▂▃▂▁▂▂▃▄█████</td></tr><tr><td>val_macro_f1</td><td>▁▄▄▄▆▆▅▆▅▆▇▇█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.00026</td></tr><tr><td>val_acc</td><td>0.97909</td></tr><tr><td>val_loss</td><td>0.05559</td></tr><tr><td>val_macro_f1</td><td>0.89739</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-fire-4</strong> at: <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yabn4zwj' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/yabn4zwj</a><br> View project at: <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251210_195308-yabn4zwj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\wandb\\run-20251211_012505-4367f206</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/4367f206' target=\"_blank\">polished-frost-5</a></strong> to <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/4367f206' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/4367f206</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:37<00:00,  3.87it/s]\n",
      "Epoch 1/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:02<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.1027 | Val Loss 0.0536 | Val Acc 0.9610 | Val F1 0.7135\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:49<00:00,  3.83it/s]\n",
      "Epoch 2/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:03<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.0554 | Val Loss 0.0543 | Val Acc 0.9615 | Val F1 0.6436\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:50<00:00,  3.83it/s]\n",
      "Epoch 3/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:04<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.0450 | Val Loss 0.0550 | Val Acc 0.9612 | Val F1 0.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:51<00:00,  3.82it/s]\n",
      "Epoch 4/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:03<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.0372 | Val Loss 0.0447 | Val Acc 0.9652 | Val F1 0.7790\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:31<00:00,  3.89it/s]\n",
      "Epoch 5/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:01<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.0311 | Val Loss 0.0441 | Val Acc 0.9644 | Val F1 0.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:08<00:00,  3.98it/s]\n",
      "Epoch 6/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.0245 | Val Loss 0.0463 | Val Acc 0.9671 | Val F1 0.8201\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:09<00:00,  3.97it/s]\n",
      "Epoch 7/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.0188 | Val Loss 0.0470 | Val Acc 0.9677 | Val F1 0.8049\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:09<00:00,  3.97it/s]\n",
      "Epoch 8/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.0138 | Val Loss 0.0464 | Val Acc 0.9723 | Val F1 0.8137\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [18:09<00:00,  3.97it/s]\n",
      "Epoch 9/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.0086 | Val Loss 0.0514 | Val Acc 0.9688 | Val F1 0.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [18:09<00:00,  3.97it/s]\n",
      "Epoch 10/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0050 | Val Loss 0.0539 | Val Acc 0.9699 | Val F1 0.8309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [18:08<00:00,  3.98it/s]\n",
      "Epoch 11/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.0028 | Val Loss 0.0648 | Val Acc 0.9710 | Val F1 0.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [18:09<00:00,  3.97it/s]\n",
      "Epoch 12/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.0011 | Val Loss 0.0765 | Val Acc 0.9706 | Val F1 0.8352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [18:10<00:00,  3.97it/s]\n",
      "Epoch 13/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.0005 | Val Loss 0.0874 | Val Acc 0.9711 | Val F1 0.8357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [18:09<00:00,  3.97it/s]\n",
      "Epoch 14/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.0002 | Val Loss 0.0918 | Val Acc 0.9715 | Val F1 0.8408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [18:09<00:00,  3.97it/s]\n",
      "Epoch 15/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [01:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.0001 | Val Loss 0.0938 | Val Acc 0.9724 | Val F1 0.8445\n",
      "Saved best model!\n",
      "Baseline 4 done! Check WandB.\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # None for no weights\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()\n",
    "\n",
    "# Baseline 4 Model: DualViTBase (concat to 6 channels, Vision Transformer Base)\n",
    "class DualViTBase(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "        self.backbone.patch_embed.proj = nn.Conv2d(6, 768, kernel_size=16, stride=16)  # 6 channels input\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        x = torch.cat([raw, defect], dim=1)  # (B, 6, 224, 224)\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Training function for Baseline 4 \n",
    "def train_baseline4(epochs=15, batch_size=32, lr=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    model = DualViTBase(num_classes=9).to(device)\n",
    "    criterion = FocalLoss(gamma=2.0).to(device)  # Without weights\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # from torch.cuda.amp import autocast, GradScaler\n",
    "    # scaler = GradScaler()\n",
    "    \n",
    "    wandb.init(project=\"wm811k-baseline\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"model\": \"ViT-Base\"})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # with autocast():  \n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scaler.scale(loss).backward()  # for mixed precision\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/vit_base_best.pth\")  # Saves to models/ dir\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"Baseline 4 done! Check WandB.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_baseline4(epochs=15, batch_size=32, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8725d2fb",
   "metadata": {},
   "source": [
    "## EfficientNet base (baseline 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb163def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: asifakbarzishan14 (asifakbarzishan14-north-south-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\wandb\\run-20251211_110857-0wojg17r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/0wojg17r' target=\"_blank\">efficient-paper-7</a></strong> to <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/0wojg17r' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-baseline/runs/0wojg17r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [12:03<00:00,  5.98it/s]\n",
      "Epoch 1/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.0778 | Val Loss 0.0405 | Val Acc 0.9682 | Val F1 0.8240\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [11:42<00:00,  6.16it/s]\n",
      "Epoch 2/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.0260 | Val Loss 0.0340 | Val Acc 0.9739 | Val F1 0.8474\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [11:41<00:00,  6.17it/s]\n",
      "Epoch 3/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.0136 | Val Loss 0.0385 | Val Acc 0.9714 | Val F1 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [11:42<00:00,  6.16it/s]\n",
      "Epoch 4/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.0069 | Val Loss 0.0401 | Val Acc 0.9752 | Val F1 0.8623\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [11:42<00:00,  6.16it/s]\n",
      "Epoch 5/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.0043 | Val Loss 0.0472 | Val Acc 0.9717 | Val F1 0.8640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [11:42<00:00,  6.16it/s]\n",
      "Epoch 6/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss 0.0030 | Val Loss 0.0516 | Val Acc 0.9739 | Val F1 0.8687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [11:43<00:00,  6.15it/s]\n",
      "Epoch 7/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss 0.0019 | Val Loss 0.0556 | Val Acc 0.9743 | Val F1 0.8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [11:41<00:00,  6.17it/s]\n",
      "Epoch 8/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss 0.0013 | Val Loss 0.0561 | Val Acc 0.9771 | Val F1 0.8939\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 Train: 100%|████████████████████████████████████████████████████████████| 4329/4329 [11:41<00:00,  6.17it/s]\n",
      "Epoch 9/15 Val: 100%|████████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss 0.0009 | Val Loss 0.0559 | Val Acc 0.9762 | Val F1 0.8720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [11:42<00:00,  6.16it/s]\n",
      "Epoch 10/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss 0.0005 | Val Loss 0.0564 | Val Acc 0.9771 | Val F1 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [11:42<00:00,  6.16it/s]\n",
      "Epoch 11/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss 0.0002 | Val Loss 0.0617 | Val Acc 0.9764 | Val F1 0.8728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [11:43<00:00,  6.15it/s]\n",
      "Epoch 12/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss 0.0002 | Val Loss 0.0613 | Val Acc 0.9777 | Val F1 0.8911\n",
      "Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [11:42<00:00,  6.16it/s]\n",
      "Epoch 13/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss 0.0001 | Val Loss 0.0597 | Val Acc 0.9777 | Val F1 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [11:43<00:00,  6.15it/s]\n",
      "Epoch 14/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss 0.0001 | Val Loss 0.0620 | Val Acc 0.9775 | Val F1 0.8956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 Train: 100%|███████████████████████████████████████████████████████████| 4329/4329 [11:42<00:00,  6.16it/s]\n",
      "Epoch 15/15 Val: 100%|███████████████████████████████████████████████████████████████| 264/264 [00:44<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss 0.0001 | Val Loss 0.0607 | Val Acc 0.9781 | Val F1 0.8936\n",
      "Saved best model!\n",
      "EfficientNet baseline done! Check WandB.\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # None for no weights\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()\n",
    "\n",
    "# Baseline EfficientNet Model: DualEfficientNetB4 (concat to 6 channels)\n",
    "class DualEfficientNetB4(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('efficientnet_b4', pretrained=True, num_classes=num_classes)\n",
    "        self.backbone.conv_stem = nn.Conv2d(6, 48, kernel_size=3, stride=2, padding=1, bias=False)  # 6 channels input\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        x = torch.cat([raw, defect], dim=1)  # (B, 6, 224, 224)\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Training function for Baseline EfficientNet\n",
    "def train_efficientnet(epochs=15, batch_size=32, lr=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    model = DualEfficientNetB4(num_classes=9).to(device)\n",
    "    criterion = FocalLoss(gamma=2.0).to(device)  # Without weights\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # from torch.cuda.amp import autocast, GradScaler\n",
    "    # scaler = GradScaler()\n",
    "    \n",
    "    wandb.init(project=\"wm811k-baseline\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"model\": \"EfficientNet-B4\"})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # with autocast():  # for mixed precision\n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scaler.scale(loss).backward()  # for mixed precision\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/efficientnet_b4_best.pth\")  # Saves to models/ dir\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"EfficientNet baseline done! Check WandB.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_efficientnet(epochs=15, batch_size=32, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f327ef",
   "metadata": {},
   "source": [
    "## Late Fusion model Using Convnext and swin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f599368e-ee46-48fb-89a6-5b991af734f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:218: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "wandb: Currently logged in as: asifakbarzishan14 (asifakbarzishan14-north-south-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\User\\Desktop\\CSE 465\\Project\\anamolies-detection-in-wafers-using-deep-learning-appraoch\\wandb\\run-20251213_220052-u9cnlysd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-fusion/runs/u9cnlysd' target=\"_blank\">fusion_base_run</a></strong> to <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-fusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-fusion' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-fusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-fusion/runs/u9cnlysd' target=\"_blank\">https://wandb.ai/asifakbarzishan14-north-south-university/wm811k-fusion/runs/u9cnlysd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [22:18<00:00,  8.63it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.0497 | Val Loss=0.0354 | Acc=0.9741 | F1=0.8468\n",
      "✓ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 2/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [21:53<00:00,  8.79it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:07<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.0274 | Val Loss=0.0367 | Acc=0.9714 | F1=0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 3/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [22:48<00:00,  8.43it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:07<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0202 | Val Loss=0.0309 | Acc=0.9750 | F1=0.8713\n",
      "✓ Saved best model\n",
      "Unfreezing defect branch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 4/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [37:13<00:00,  5.17it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:07<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.0159 | Val Loss=0.0408 | Acc=0.9688 | F1=0.8552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 5/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [36:56<00:00,  5.21it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:06<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.0122 | Val Loss=0.0408 | Acc=0.9700 | F1=0.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 6/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [36:48<00:00,  5.23it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:07<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.0103 | Val Loss=0.0401 | Acc=0.9724 | F1=0.8608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 7/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [36:43<00:00,  5.24it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:09<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.0082 | Val Loss=0.0309 | Acc=0.9748 | F1=0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 8/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [36:16<00:00,  5.30it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.0067 | Val Loss=0.0399 | Acc=0.9746 | F1=0.8735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 9/15 Train: 100%|██████████████████████████████████████████████████████████| 11542/11542 [36:12<00:00,  5.31it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.0055 | Val Loss=0.0428 | Acc=0.9777 | F1=0.8869\n",
      "✓ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 10/15 Train: 100%|█████████████████████████████████████████████████████████| 11542/11542 [36:14<00:00,  5.31it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.0051 | Val Loss=0.0440 | Acc=0.9768 | F1=0.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 11/15 Train: 100%|█████████████████████████████████████████████████████████| 11542/11542 [36:06<00:00,  5.33it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.0047 | Val Loss=0.0529 | Acc=0.9737 | F1=0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 12/15 Train: 100%|█████████████████████████████████████████████████████████| 11542/11542 [36:09<00:00,  5.32it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.0043 | Val Loss=0.0528 | Acc=0.9774 | F1=0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 13/15 Train: 100%|█████████████████████████████████████████████████████████| 11542/11542 [36:13<00:00,  5.31it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.0038 | Val Loss=0.0481 | Acc=0.9778 | F1=0.8989\n",
      "✓ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 14/15 Train: 100%|█████████████████████████████████████████████████████████| 11542/11542 [36:10<00:00,  5.32it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.0039 | Val Loss=0.0602 | Acc=0.9771 | F1=0.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:259: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 15/15 Train: 100%|█████████████████████████████████████████████████████████| 11542/11542 [36:13<00:00,  5.31it/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25956\\1405085622.py:284: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 702/702 [01:05<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.0036 | Val Loss=0.0731 | Acc=0.9764 | F1=0.8684\n",
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from torch.utils.data import DataLoader\n",
    "# import timm  # For pretrained models\n",
    "# from tqdm import tqdm  # Progress bars\n",
    "# import wandb\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Focal Loss without class weights\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "#         super().__init__()\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha  # None for no weights\n",
    "#         self.reduction = reduction\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "#         if self.alpha is not None:\n",
    "#             focal_loss = self.alpha[targets] * focal_loss\n",
    "#         if self.reduction == 'mean':\n",
    "#             return focal_loss.mean()\n",
    "#         return focal_loss.sum()\n",
    "\n",
    "# # Fusion Model: ConvNeXt-Base (raw) + Swin-Base (defect) – Late Fusion\n",
    "# class FusionModel(nn.Module):\n",
    "#     def __init__(self, num_classes=9):\n",
    "#         super().__init__()\n",
    "#         self.raw_branch = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=True, num_classes=0)  # 1024 features\n",
    "#         self.defect_branch = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=True, num_classes=0)  # 1024 features\n",
    "        \n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.LayerNorm(2048),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(2048, 512),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(512, num_classes)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, raw, defect):\n",
    "#         f_raw = self.raw_branch(raw)  # (B, 1024)\n",
    "#         f_defect = self.defect_branch(defect)  # (B, 1024)\n",
    "#         fused = torch.cat([f_raw, f_defect], dim=1)  # (B, 2048)\n",
    "#         return self.classifier(fused)\n",
    "\n",
    "# # Training function for Fusion Model (uses your get_dataloaders)\n",
    "# def train_fusion(epochs=15, batch_size=32, lr=1e-4):\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "    \n",
    "#     train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "#     model = FusionModel(num_classes=9).to(device)\n",
    "#     criterion = FocalLoss(gamma=2.0).to(device)  # Without weights\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "#     scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "#     wandb.init(project=\"wm811k-fusion\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"model\": \"ConvNeXtB-SwinB-Fusion\"})\n",
    "#     wandb.watch(model)\n",
    "    \n",
    "#     best_val_acc = 0.0\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         train_loss = 0.0\n",
    "#         for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "#             raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#           #  with autocast(): // no mixed precision\n",
    "#                 outputs = model(raw, defect)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#             # scaler.scale(loss).backward()\n",
    "#             # scaler.step(optimizer)\n",
    "#             # scaler.update()\n",
    "#             train_loss += loss.item()\n",
    "        \n",
    "#         train_loss /= len(train_dl)\n",
    "        \n",
    "#         model.eval()\n",
    "#         val_preds, val_labels = [], []\n",
    "#         val_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "#                 raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "#                 with autocast():\n",
    "#                     outputs = model(raw, defect)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item()\n",
    "#                 preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "#                 val_preds.extend(preds)\n",
    "#                 val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "#         val_loss /= len(val_dl)\n",
    "#         val_acc = accuracy_score(val_labels, val_preds)\n",
    "#         val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "#         wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "#                    \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "#         print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "#         if val_acc > best_val_acc:\n",
    "#             best_val_acc = val_acc\n",
    "#             torch.save(model.state_dict(), \"models/fusion_best.pth\")  # Save to models/ dir\n",
    "#             print(\"Saved best model!\")\n",
    "        \n",
    "#         scheduler.step()\n",
    "    \n",
    "#     train_dl.dataset.close()\n",
    "#     val_dl.dataset.close()\n",
    "    \n",
    "#     print(\"Fusion training done! Check WandB.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_fusion(epochs=15, batch_size=32, lr=1e-4)\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import wandb\n",
    "\n",
    "# FOCAL LOSS \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = self.ce(logits, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            loss = self.alpha[targets] * loss\n",
    "        return loss.mean() if self.reduction == \"mean\" else loss.sum()\n",
    "\n",
    "\n",
    "# BASE DUAL FUSION MODEL (WITH CHECKPOINTING)\n",
    "class DualFusion(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "\n",
    "        self.raw_branch = timm.create_model(\n",
    "            \"convnext_base.fb_in22k_ft_in1k\",\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "\n",
    "        self.defect_branch = timm.create_model(\n",
    "            \"swin_base_patch4_window7_224.ms_in22k_ft_in1k\",\n",
    "            pretrained=True,\n",
    "            num_classes=0\n",
    "        )\n",
    "\n",
    "        self.raw_branch.set_grad_checkpointing(True)\n",
    "        self.defect_branch.set_grad_checkpointing(True)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(2048),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, raw, defect):\n",
    "        f_raw = self.raw_branch(raw)\n",
    "        f_defect = self.defect_branch(defect)\n",
    "        fused = torch.cat([f_raw, f_defect], dim=1)\n",
    "        return self.classifier(fused)\n",
    "\n",
    "\n",
    "# TRAINING FUNCTION\n",
    "def train_fusion(\n",
    "    epochs=15,\n",
    "    batch_size=12,    # Changed to 12\n",
    "    accum_steps=1,    # effective batch = 12\n",
    "    lr=1e-4,\n",
    "    freeze_epochs=3\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "\n",
    "    model = DualFusion(num_classes=9).to(device)\n",
    "\n",
    "    # Freeze defect branch initially\n",
    "    for p in model.defect_branch.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    criterion = FocalLoss(gamma=2.0).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=lr,\n",
    "        weight_decay=0.01\n",
    "    )\n",
    "\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # ------------------- wandb -------------------\n",
    "    wandb.init(\n",
    "        project=\"wm811k-fusion\",\n",
    "        name=\"fusion_base_run\",\n",
    "        config={\n",
    "            \"epochs\": epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"accum_steps\": accum_steps,\n",
    "            \"lr\": lr,\n",
    "            \"freeze_epochs\": freeze_epochs,\n",
    "            \"model\": \"DualFusion-ConvNeXt+Swin\"\n",
    "        }\n",
    "    )\n",
    "    wandb.watch(model)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Unfreeze after freeze_epochs\n",
    "        if epoch == freeze_epochs:\n",
    "            print(\"Unfreezing defect branch...\")\n",
    "            for p in model.defect_branch.parameters():\n",
    "                p.requires_grad = True\n",
    "            optimizer = optim.AdamW(\n",
    "                model.parameters(), lr=lr, weight_decay=0.01\n",
    "            )\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for step, (raw, defect, labels) in enumerate(\n",
    "            tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\")\n",
    "        ):\n",
    "            raw = raw.to(device, non_blocking=True)\n",
    "            defect = defect.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels) / accum_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            train_loss += loss.item() * accum_steps\n",
    "\n",
    "            if (step + 1) % accum_steps == 0 or (step + 1) == len(train_dl):\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        train_loss /= len(train_dl)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=\"Validation\"):\n",
    "                raw = raw.to(device, non_blocking=True)\n",
    "                defect = defect.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                with autocast():\n",
    "                    outputs = model(raw, defect)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average=\"macro\")\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}: \"\n",
    "            f\"Train Loss={train_loss:.4f} | \"\n",
    "            f\"Val Loss={val_loss:.4f} | \"\n",
    "            f\"Acc={val_acc:.4f} | \"\n",
    "            f\"F1={val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "        wandb.log({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_macro_f1\": val_f1,\n",
    "            \"lr\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/fusion_base_best.pth\")\n",
    "            print(\"✓ Saved best model\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    print(\"Training completed successfully.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_fusion(\n",
    "        epochs=15,\n",
    "        batch_size=12,   \n",
    "        accum_steps=2,    \n",
    "        lr=1e-4,\n",
    "        freeze_epochs=3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e5743-497d-4b3a-b545-5c831ab0e1be",
   "metadata": {},
   "source": [
    "## Running the fusion model With VAE integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d1b01-0e65-4121-9f53-fd361f5bc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        # Encoder (takes 6ch concat input like baselines)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(6, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.mu = nn.Linear(512, latent_dim)\n",
    "        self.logvar = nn.Linear(512, latent_dim)\n",
    "        \n",
    "        # Decoder (for pretraining)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128 * 28 * 28),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (128, 28, 28)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 6, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid()  # Output [0,1] for normalized images\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = self.mu(h), self.logvar(h)\n",
    "        z = mu + torch.exp(0.5 * logvar) * torch.randn_like(logvar)\n",
    "        return z, mu, logvar\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        return self.decoder(z), mu, logvar\n",
    "\n",
    "# Pretrain VAE function\n",
    "def pretrain_vae(epochs=5, batch_size=32, lr=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    vae = VAE().to(device)\n",
    "    optimizer = optim.AdamW(vae.parameters(), lr=lr)\n",
    "    \n",
    "    train_dl, _, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        vae.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, _ in tqdm(train_dl, desc=f\"VAE Epoch {epoch+1}/{epochs}\"):\n",
    "            x = torch.cat([raw, defect], dim=1).to(device)  # (B, 6, 224, 224)\n",
    "            optimizer.zero_grad()\n",
    "            recon, mu, logvar = vae(x)\n",
    "            recon_loss = nn.MSELoss()(recon, x)\n",
    "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            loss = recon_loss + 0.001 * kl_loss  # Beta=0.001 for balance\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        print(f\"VAE Epoch {epoch+1}: Loss {train_loss / len(train_dl):.4f}\")\n",
    "    \n",
    "    torch.save(vae.state_dict(), \"models/vae_pretrained.pth\")\n",
    "    print(\"VAE pretrained and saved!\")\n",
    "\n",
    "# Fusion Model with VAE Encoder\n",
    "class FusionWithVAE(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.raw_branch = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=True, num_classes=0)\n",
    "        self.defect_branch = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=True, num_classes=0)\n",
    "        self.vae_encoder = VAE()  # Load pretrained encoder\n",
    "        \n",
    "        # Fusion head with VAE latent (2048 + 128 = 2176)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(2176),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2176, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        f_raw = self.raw_branch(raw)\n",
    "        f_defect = self.defect_branch(defect)\n",
    "        x_concat = torch.cat([raw, defect], dim=1)\n",
    "        vae_latent, _, _ = self.vae_encoder.encode(x_concat)\n",
    "        fused = torch.cat([f_raw, f_defect, vae_latent], dim=1)  # 1024 + 1024 + 128\n",
    "        return self.classifier(fused)\n",
    "\n",
    "# Training function for Fusion with VAE\n",
    "def train_fusion_vae(epochs=15, batch_size=32, lr=1e-4):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    model = FusionWithVAE(num_classes=9).to(device)\n",
    "    # Load pretrained VAE\n",
    "    model.vae_encoder.load_state_dict(torch.load(\"models/vae_pretrained.pth\"))\n",
    "    model.vae_encoder.eval()  # Freeze VAE during fusion training\n",
    "    \n",
    "    criterion = FocalLoss(gamma=2.0).to(device)  # Without weights\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    wandb.init(project=\"wm811k-fusion\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"model\": \"Fusion-VAE\"})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # with autocast():  # Uncomment for mixed precision\n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/fusion_vae_best.pth\")  # Save to models/ dir\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"Fusion with VAE done! Check WandB.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # pretrain VAE \n",
    "    pretrain_vae(epochs=5, batch_size=32, lr=1e-4)\n",
    "    # train fusion with VAE\n",
    "    train_fusion_vae(epochs=15, batch_size=32, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e28d4-e6a7-4661-a757-ae0c3a5bea09",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning with dropout parameters (using grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74cc2b-3529-4ef5-a4dd-e62dc87a40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset  # For small subsets\n",
    "\n",
    "# Modified FusionModel to accept tunable dropout rates\n",
    "class FusionModelTunable(nn.Module):\n",
    "    def __init__(self, num_classes=9, dropout1=0.3, dropout2=0.2):\n",
    "        super().__init__()\n",
    "        self.raw_branch = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=True, num_classes=0)  # 1024 features\n",
    "        self.defect_branch = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=True, num_classes=0)  # 1024 features\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(2048),\n",
    "            nn.Dropout(dropout1),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        f_raw = self.raw_branch(raw)  # (B, 1024)\n",
    "        f_defect = self.defect_branch(defect)  # (B, 1024)\n",
    "        fused = torch.cat([f_raw, f_defect], dim=1)  # (B, 2048)\n",
    "        return self.classifier(fused)\n",
    "\n",
    "# Simple Grid Search for Hyperparams (on small data subset)\n",
    "def grid_search_fusion():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    lrs = [1e-4, 5e-5, 1e-5]\n",
    "    batch_sizes = [16, 32]\n",
    "    gammas = [2.0, 3.0]\n",
    "    dropout1s = [0.1, 0.3, 0.5]  # Tune first dropout\n",
    "    dropout2s = [0.1, 0.2, 0.3]  # Tune second dropout\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    best_params = {}\n",
    "    \n",
    "    # Load full datasets once, then subset\n",
    "    train_dl_full, val_dl_full, _ = get_dataloaders(batch_size=32)  # Temp load to get datasets\n",
    "    train_dataset = train_dl_full.dataset\n",
    "    val_dataset = val_dl_full.dataset\n",
    "    \n",
    "    # Small subsets for speed (e.g., 1000 train, 500 val samples)\n",
    "    train_indices = list(range(1000))\n",
    "    val_indices = list(range(500))\n",
    "    train_subset = Subset(train_dataset, train_indices)\n",
    "    val_subset = Subset(val_dataset, val_indices)\n",
    "    \n",
    "    for lr in lrs:\n",
    "        for bs in batch_sizes:\n",
    "            for gamma in gammas:\n",
    "                for dropout1 in dropout1s:\n",
    "                    for dropout2 in dropout2s:\n",
    "                        print(f\"Testing lr={lr}, batch={bs}, gamma={gamma}, dropout1={dropout1}, dropout2={dropout2}\")\n",
    "                        \n",
    "                        # Create dataloaders for this batch_size on subsets\n",
    "                        train_dl = DataLoader(train_subset, batch_size=bs, shuffle=True, num_workers=0, pin_memory=True)\n",
    "                        val_dl = DataLoader(val_subset, batch_size=bs, shuffle=False, num_workers=0, pin_memory=True)\n",
    "                        \n",
    "                        model = FusionModelTunable(num_classes=9, dropout1=dropout1, dropout2=dropout2).to(device)\n",
    "                        criterion = FocalLoss(gamma=gamma).to(device)\n",
    "                        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "                        \n",
    "                        # Train for 2 epochs only for tuning\n",
    "                        for epoch in range(2):\n",
    "                            model.train()\n",
    "                            train_loss = 0.0\n",
    "                            for raw, defect, labels in tqdm(train_dl, desc=f\"Tune Epoch {epoch+1}/2 Train\"):\n",
    "                                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                                optimizer.zero_grad()\n",
    "                                outputs = model(raw, defect)\n",
    "                                loss = criterion(outputs, labels)\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "                                train_loss += loss.item()\n",
    "                            train_loss /= len(train_dl)\n",
    "                            print(f\"Tune Epoch {epoch+1} Train Loss: {train_loss:.4f}\")\n",
    "                        \n",
    "                        # Val loop (get val_acc)\n",
    "                        model.eval()\n",
    "                        val_preds, val_labels = [], []\n",
    "                        val_loss = 0.0\n",
    "                        with torch.no_grad():\n",
    "                            for raw, defect, labels in tqdm(val_dl, desc=\"Tune Val\"):\n",
    "                                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                                outputs = model(raw, defect)\n",
    "                                loss = criterion(outputs, labels)\n",
    "                                val_loss += loss.item()\n",
    "                                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                                val_preds.extend(preds)\n",
    "                                val_labels.extend(labels.cpu().numpy())\n",
    "                        \n",
    "                        val_loss /= len(val_dl)\n",
    "                        val_acc = accuracy_score(val_labels, val_preds)\n",
    "                        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "                        print(f\"Tune Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "                        \n",
    "                        if val_acc > best_acc:\n",
    "                            best_acc = val_acc\n",
    "                            best_params = {'lr': lr, 'batch_size': bs, 'gamma': gamma, 'dropout1': dropout1, 'dropout2': dropout2}\n",
    "    \n",
    "    print(f\"Best params: {best_params} with acc {best_acc}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_search_fusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944a9bc-d403-481f-aae8-a73c86369214",
   "metadata": {},
   "source": [
    "## late Fusion Model with Tunable Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af804d5c-08ce-4314-adba-5e0739c01eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, num_classes=9, dropout1=0.3, dropout2=0.2):  # hyperparameter dropout1 and dropout2 \n",
    "        super().__init__()\n",
    "        self.raw_branch = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=True, num_classes=0)  # 1024 features\n",
    "        self.defect_branch = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=True, num_classes=0)  # 1024 features\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(2048),\n",
    "            nn.Dropout(dropout1),\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        f_raw = self.raw_branch(raw)  # (B, 1024)\n",
    "        f_defect = self.defect_branch(defect)  # (B, 1024)\n",
    "        fused = torch.cat([f_raw, f_defect], dim=1)  # (B, 2048)\n",
    "        return self.classifier(fused)\n",
    "\n",
    "# Training function with tuned params (uses your get_dataloaders)\n",
    "def train_fusion_tuned(epochs=15, batch_size=32, lr=1e-4, gamma=2.0, dropout1=0.3, dropout2=0.2):  # Change batch_size, lr, gamma, dropout1, dropout2 here to your best values from grid search\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)  # Change batch_size in get_dataloaders call if needed\n",
    "    \n",
    "    model = FusionModel(num_classes=9, dropout1=dropout1, dropout2=dropout2).to(device)  # Passes tuned dropouts\n",
    "    criterion = FocalLoss(gamma=gamma).to(device)  # Without weights, gamma tuned\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)  # lr tuned\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    wandb.init(project=\"wm811k-fusion\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"gamma\": gamma, \n",
    "                                                 \"dropout1\": dropout1, \"dropout2\": dropout2, \"model\": \"Fusion-Tuned\"})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # with autocast():  # Uncomment for mixed precision\n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/fusion_tuned_best.pth\")  # Saves to models/ dir\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"Fusion with tuned params done! Check WandB.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_fusion_tuned(epochs=15, batch_size=32, lr=1e-4, gamma=2.0, dropout1=0.3, dropout2=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d780a8-3ce1-4e48-aebe-27eb8f458b3a",
   "metadata": {},
   "source": [
    "## Final Late Fusion Model with VAE Integration and Tuned Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9948e-3abd-4434-b086-9702bf8ac7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE pretraining added\n",
    "# VAE for Feature Extraction (pretrain on 6ch concat input)\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(6, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.mu = nn.Linear(512, latent_dim)\n",
    "        self.logvar = nn.Linear(512, latent_dim)\n",
    "        \n",
    "        # Decoder (for pretraining)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128 * 28 * 28),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (128, 28, 28)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 6, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = self.mu(h), self.logvar(h)\n",
    "        z = mu + torch.exp(0.5 * logvar) * torch.randn_like(logvar)\n",
    "        return z, mu, logvar\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        return self.decoder(z), mu, logvar\n",
    "\n",
    "# Pretrain VAE function\n",
    "# #####As I have tarined and saved the vae. I will be using the previous vae model#####\n",
    "# def pretrain_vae(epochs=5, batch_size=32, lr=1e-4):  # Changed epochs, batch_size, lr when tuned differently\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     vae = VAE().to(device)\n",
    "#     optimizer = optim.AdamW(vae.parameters(), lr=lr)\n",
    "    \n",
    "#     train_dl, _, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         vae.train()\n",
    "#         train_loss = 0.0\n",
    "#         for raw, defect, _ in tqdm(train_dl, desc=f\"VAE Epoch {epoch+1}/{epochs}\"):\n",
    "#             x = torch.cat([raw, defect], dim=1).to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             recon, mu, logvar = vae(x)\n",
    "#             recon_loss = nn.MSELoss()(recon, x)\n",
    "#             kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "#             loss = recon_loss + 0.001 * kl_loss\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_loss += loss.item()\n",
    "        \n",
    "#         print(f\"VAE Epoch {epoch+1}: Loss {train_loss / len(train_dl):.4f}\")\n",
    "    \n",
    "#     torch.save(vae.state_dict(), \"models/vae_pretrained.pth\")\n",
    "#     print(\"VAE pretrained and saved!\")\n",
    "\n",
    "# Fusion Model with VAE and Tunable Params\n",
    "class FusionWithVAE(nn.Module):\n",
    "    def __init__(self, num_classes=9, dropout1=0.3, dropout2=0.2):\n",
    "        super().__init__()\n",
    "        self.raw_branch = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=True, num_classes=0)  # 1024 features\n",
    "        self.defect_branch = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=True, num_classes=0)  # 1024 features\n",
    "        self.vae = VAE()  # VAE encoder\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(2048 + 128),  # 2048 fusion + 128 VAE latent\n",
    "            nn.Dropout(dropout1),  # Change dropout1 if tuned differently\n",
    "            nn.Linear(2048 + 128, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout2),  # Change dropout2 if tuned differently\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, raw, defect):\n",
    "        f_raw = self.raw_branch(raw)\n",
    "        f_defect = self.defect_branch(defect)\n",
    "        x_concat = torch.cat([raw, defect], dim=1)\n",
    "        vae_latent, _, _ = self.vae.encode(x_concat)\n",
    "        fused = torch.cat([f_raw, f_defect, vae_latent], dim=1)  # 2048 + 128\n",
    "        return self.classifier(fused)\n",
    "\n",
    "# Training function with tuned params (uses your get_dataloaders)\n",
    "def train_fusion_vae_tuned(epochs=15, batch_size=32, lr=1e-4, gamma=2.0, dropout1=0.3, dropout2=0.2):  # Changed batch_size, lr, gamma, dropout1, dropout2 here to your best values from grid search\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "    \n",
    "    model = FusionWithVAE(num_classes=9, dropout1=dropout1, dropout2=dropout2).to(device)\n",
    "    model.vae.load_state_dict(torch.load(\"models/vae_pretrained.pth\"))  # Load pretrained VAE\n",
    "    model.vae.eval()  # Freeze VAE\n",
    "    criterion = FocalLoss(gamma=gamma).to(device)  # Without weights\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    wandb.init(project=\"wm811k-fusion\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"gamma\": gamma, \n",
    "                                                 \"dropout1\": dropout1, \"dropout2\": dropout2, \"model\": \"Fusion-VAE-Tuned\"})\n",
    "    wandb.watch(model)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for raw, defect, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\"):\n",
    "            raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # with autocast():  # Uncomment for mixed precision\n",
    "            outputs = model(raw, defect)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scaler.scale(loss).backward()  # Uncomment these 3 lines for mixed precision\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_dl)\n",
    "        \n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "                raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/fusion_vae_tuned_best.pth\")  # Saves to models/ dir\n",
    "            print(\"Saved best model!\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    train_dl.dataset.close()\n",
    "    val_dl.dataset.close()\n",
    "    \n",
    "    print(\"Fusion with VAE and tuned params done! Check WandB.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pretrain_vae(epochs=5, batch_size=32, lr=1e-4)  # Pretrain VAE first (change if needed)\n",
    "    train_fusion_vae_tuned(epochs=15, batch_size=32, lr=1e-4, gamma=2.0, dropout1=0.3, dropout2=0.2)  # Change to your tuned params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d000a5-cd5a-417b-a8fd-e8d18077431e",
   "metadata": {},
   "source": [
    "## Install libraries <br>\n",
    "pip install captum -----> For Grad-CAM (PyTorch XAI) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99c5da-40a2-4026-be19-b5ecd1a05821",
   "metadata": {},
   "source": [
    "## using exaplianable AI to explain all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1755ced4-690a-40e6-be5e-8ddebe2c3597",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (266197858.py, line 156)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 156\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpred = int(output.argmax(dim=1).item())1\u001b[39m\n                                           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# UNIVERSAL XAI — DUAL-INPUT (FULL CODE)\n",
    "# Run this cell once, then call explain_model(\"your_path.pth\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import LayerGradCam, LayerAttribution\n",
    "\n",
    "# NOTE: get_dataloaders(batch_size) must be defined in your notebook/script.\n",
    "# It should return (train_dl, val_dl, test_dl) where each batch yields (raw, defect, label).\n",
    "# If your dataloader returns a different layout, adapt accordingly.\n",
    "\n",
    "def explain_model(model_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    p = model_path.lower()\n",
    "\n",
    "    # -------------------------------\n",
    "    # DUAL RESNET50\n",
    "    # -------------------------------\n",
    "    if 'resnet50' in p:\n",
    "        class DualResNet50(nn.Module):\n",
    "            def __init__(self, num_classes=9):\n",
    "                super().__init__()\n",
    "                self.backbone = timm.create_model('resnet50', pretrained=False, num_classes=num_classes)\n",
    "                # change first conv to accept 6-channel input (raw + defect)\n",
    "                self.backbone.conv1 = nn.Conv2d(6, 64, 7, 2, 3, bias=False)\n",
    "            def forward(self, r, d):\n",
    "                return self.backbone(torch.cat([r, d], 1))\n",
    "        model = DualResNet50()\n",
    "        target_layer = model.backbone.layer4[-1]\n",
    "\n",
    "    # -------------------------------\n",
    "    # DUAL CONVNEXT\n",
    "    # -------------------------------\n",
    "    elif 'convnext' in p:\n",
    "        class DualConvNeXt(nn.Module):\n",
    "            def __init__(self, num_classes=9):\n",
    "                super().__init__()\n",
    "                self.backbone = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=False, num_classes=num_classes)\n",
    "                self.backbone.stem[0] = nn.Conv2d(6, 128, 4, 4)\n",
    "            def forward(self, r, d):\n",
    "                return self.backbone(torch.cat([r, d], 1))\n",
    "        model = DualConvNeXt()\n",
    "        target_layer = model.backbone.stages[-1]\n",
    "\n",
    "    # -------------------------------\n",
    "    # DUAL SWIN\n",
    "    # -------------------------------\n",
    "    elif 'swin' in p:\n",
    "        class DualSwin(nn.Module):\n",
    "            def __init__(self, num_classes=9):\n",
    "                super().__init__()\n",
    "                self.backbone = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=False, num_classes=num_classes)\n",
    "                self.backbone.patch_embed.proj = nn.Conv2d(6, 128, 4, 4)\n",
    "            def forward(self, r, d):\n",
    "                return self.backbone(torch.cat([r, d], 1))\n",
    "        model = DualSwin()\n",
    "        target_layer = model.backbone.layers[-1].blocks[-1].norm1\n",
    "\n",
    "    # -------------------------------\n",
    "    # DUAL VIT\n",
    "    # -------------------------------\n",
    "    elif 'vit' in p:\n",
    "        class DualViT(nn.Module):\n",
    "            def __init__(self, num_classes=9):\n",
    "                super().__init__()\n",
    "                self.backbone = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "                self.backbone.patch_embed.proj = nn.Conv2d(6, 768, 16, 16)\n",
    "            def forward(self, r, d):\n",
    "                return self.backbone(torch.cat([r, d], 1))\n",
    "        model = DualViT()\n",
    "        target_layer = model.backbone.blocks[-1].norm1\n",
    "\n",
    "    # -------------------------------\n",
    "    # DUAL EFFICIENTNET\n",
    "    # -------------------------------\n",
    "    elif 'efficientnet' in p:\n",
    "        class DualEffNet(nn.Module):\n",
    "            def __init__(self, num_classes=9):\n",
    "                super().__init__()\n",
    "                self.backbone = timm.create_model('efficientnet_b4', pretrained=False, num_classes=num_classes)\n",
    "                self.backbone.conv_stem = nn.Conv2d(6, 48, 3, 2, 1, bias=False)\n",
    "            def forward(self, r, d):\n",
    "                return self.backbone(torch.cat([r, d], 1))\n",
    "        model = DualEffNet()\n",
    "        # choose a conv-expansion layer as target\n",
    "        target_layer = model.backbone.blocks[-1][-1].conv_exp\n",
    "\n",
    "    # -------------------------------\n",
    "    # FUSION MODEL (two separate backbones + classifier)\n",
    "    # -------------------------------\n",
    "    elif 'fusion' in p:\n",
    "        class FusionModel(nn.Module):\n",
    "            def __init__(self, use_vae=False):\n",
    "                super().__init__()\n",
    "                self.use_vae = use_vae\n",
    "                # raw_branch returns features (num_classes=0)\n",
    "                self.raw_branch = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=False, num_classes=0)\n",
    "                # defect_branch returns features\n",
    "                self.defect_branch = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=False, num_classes=0)\n",
    "                if use_vae:\n",
    "                    # Provide VAE class in your code if you use \"vae\" mode.\n",
    "                    self.vae = VAE()\n",
    "                dim = 2048 + (128 if use_vae else 0)\n",
    "                self.classifier = nn.Sequential(\n",
    "                    nn.LayerNorm(dim),\n",
    "                    nn.Dropout(0.3),\n",
    "                    nn.Linear(dim, 512),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(512, 9)\n",
    "                )\n",
    "            def forward(self, r, d):\n",
    "                # both branches accept single-input tensors (e.g., r and d)\n",
    "                f1 = self.raw_branch(r)\n",
    "                f2 = self.defect_branch(d)\n",
    "                if self.use_vae:\n",
    "                    z, _, _ = self.vae.encode(torch.cat([r, d], 1))\n",
    "                    f = torch.cat([f1, f2, z], 1)\n",
    "                else:\n",
    "                    f = torch.cat([f1, f2], 1)\n",
    "                return self.classifier(f)\n",
    "        model = FusionModel(use_vae=('vae' in p))\n",
    "        target_layer_raw = model.raw_branch.stages[-1]\n",
    "        target_layer_defect = model.defect_branch.layers[-1].blocks[-1].norm1\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Model type not recognized in model_path. Include 'resnet50', 'convnext', 'swin', 'vit', 'efficientnet' or 'fusion' in filename.\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Load weights\n",
    "    # -------------------------------\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded: {model_path}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Get one sample (force batch_size=1)\n",
    "    # -------------------------------\n",
    "    _, val_dl, _ = get_dataloaders(batch_size=1)\n",
    "    raw, defect, label = next(iter(val_dl))\n",
    "    raw = raw.to(device)\n",
    "    defect = defect.to(device)\n",
    "    # label keep on cpu for safe handling\n",
    "    label_cpu = label.cpu()\n",
    "\n",
    "    # -------------------------------\n",
    "    # Prediction\n",
    "    # -------------------------------\n",
    "    with torch.no_grad():\n",
    "        output = model(raw, defect)\n",
    "        pred = int(output.argmax(dim=1).item())1\n",
    "\n",
    "    # Universal label extraction (works for many shapes: scalar, [1], [1,2], one-hot etc.)\n",
    "    # If labels are one-hot vectors, .argmax will return the class index.\n",
    "    lab = label_cpu.view(-1)\n",
    "    if lab.numel() == 0:\n",
    "        raise RuntimeError(\"Label tensor empty\")\n",
    "    # if label is one-hot or multi-class one-hot-like (length > 1 and sums to 1), convert to argmax\n",
    "    if lab.numel() > 1 and ((lab.dtype.is_floating_point and torch.isclose(lab.sum(), torch.tensor(1.0))) or (not lab.dtype.is_floating_point and lab.sum() == 1)):\n",
    "        true_label = int(lab.argmax().item())\n",
    "    else:\n",
    "        true_label = int(lab[0].item())\n",
    "\n",
    "    print(f\"True label: {true_label} → Predicted: {pred}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Visualization helper\n",
    "    # -------------------------------\n",
    "    def show_cam(img_tensor, attr_map, title):\n",
    "        # attr_map: single-channel 2D numpy or torch arr (H,W)\n",
    "        if isinstance(attr_map, torch.Tensor):\n",
    "            attr_map = attr_map.detach().cpu().numpy()\n",
    "        # if attr came with channels, sum them\n",
    "        if attr_map.ndim == 3:\n",
    "            attr_map = attr_map.sum(0)\n",
    "        # normalize\n",
    "        attr_map = (attr_map - attr_map.min()) / (attr_map.max() - attr_map.min() + 1e-8)\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * attr_map), cv2.COLORMAP_JET)\n",
    "        heatmap = cv2.resize(heatmap, (224, 224))\n",
    "\n",
    "        img_np = img_tensor[0].detach().cpu().permute(1, 2, 0).numpy()\n",
    "        img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-8)\n",
    "        img_disp = np.uint8(255 * img_np)\n",
    "\n",
    "        overlay = (0.6 * img_disp.astype(np.float32) + 0.4 * heatmap.astype(np.float32)).astype(np.uint8)\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1); plt.imshow(img_np); plt.title(\"Input\"); plt.axis('off')\n",
    "        plt.subplot(1, 2, 2); plt.imshow(overlay); plt.title(title); plt.axis('off')\n",
    "        plt.suptitle(f\"Pred: {pred} | True: {true_label}\", fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "    # -------------------------------\n",
    "    # Grad-CAM via Captum (multi-input usage)\n",
    "    # -------------------------------\n",
    "    if 'fusion' in p:\n",
    "        # Raw branch Grad-CAM\n",
    "        gc_raw = LayerGradCam(model, target_layer_raw)\n",
    "        # pass both inputs as a tuple for a multi-input forward\n",
    "        attr_raw = gc_raw.attribute(inputs=(raw, defect), target=pred)\n",
    "        # Interpolate / resize attribution to image size and reduce to 2D\n",
    "        attr_raw = LayerAttribution.interpolate(attr_raw, (224, 224))[0].sum(0)\n",
    "        show_cam(raw, attr_raw, \"Grad-CAM: Raw Branch\")\n",
    "\n",
    "        # Defect branch Grad-CAM\n",
    "        gc_def = LayerGradCam(model, target_layer_defect)\n",
    "        attr_def = gc_def.attribute(inputs=(raw, defect), target=pred)\n",
    "        attr_def = LayerAttribution.interpolate(attr_def, (224, 224))[0].sum(0)\n",
    "        show_cam(defect, attr_def, \"Grad-CAM: Defect Branch\")\n",
    "\n",
    "    else:\n",
    "        gc = LayerGradCam(model, target_layer)\n",
    "        # IMPORTANT: pass inputs as a tuple for dual-input forward\n",
    "        attr = gc.attribute(inputs=(raw, defect), target=pred)\n",
    "        attr = LayerAttribution.interpolate(attr, (224, 224))[0].sum(0)\n",
    "        show_cam(raw, attr, \"Grad-CAM\")\n",
    "\n",
    "    print(\"XAI complete — finished successfully!\")\n",
    "\n",
    "# -------------------------------\n",
    "# Example run (edit path as needed)\n",
    "# -------------------------------\n",
    "explain_model(\"models/resnet50_dual_best.pth\")\n",
    "# explain_model(\"models/convnext_base_best.pth\")\n",
    "# explain_model(\"models/fusion_tuned_best.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bbacd1-827e-4bde-b31b-eb6d6ccf5327",
   "metadata": {},
   "source": [
    "## testing fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d05540-eb4e-4f4c-b637-a6cb3fc3f852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_544804\\797271942.py:213: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/1 Train:   0%|                                                                       | 0/34626 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_544804\\797271942.py:230: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/1 Train: 100%|███████████████████████████████████████████████████████████| 34626/34626 [36:56<00:00, 15.62it/s]\n",
      "Validation:   0%|                                                                             | 0/2105 [00:00<?, ?it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_544804\\797271942.py:256: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████| 2105/2105 [01:45<00:00, 19.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.0814 | Val Loss=0.0367 | Acc=0.9715 | F1=0.8167\n",
      "✓ Saved best model\n",
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# # Safe Fusion Model Training – No OOM, No Warnings\n",
    "# import os\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'  # ← Add this line at top\n",
    "\n",
    "# from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# # Your FocalLoss and DualFusion class (same as before)\n",
    "# class FocalLoss(nn.Module):\n",
    "#     def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "#         super().__init__()\n",
    "#         self.gamma = gamma\n",
    "#         self.alpha = alpha\n",
    "#         self.reduction = reduction\n",
    "\n",
    "#     def forward(self, inputs, targets):\n",
    "#         ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "#         pt = torch.exp(-ce_loss)\n",
    "#         focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "#         if self.alpha is not None:\n",
    "#             focal_loss = self.alpha[targets] * focal_loss\n",
    "#         if self.reduction == 'mean':\n",
    "#             return focal_loss.mean()\n",
    "#         return focal_loss.sum()\n",
    "\n",
    "# class DualFusion(nn.Module):\n",
    "#     def __init__(self, num_classes=9):\n",
    "#         super().__init__()\n",
    "#         self.raw_branch = timm.create_model('convnext_base.fb_in22k_ft_in1k', pretrained=True, num_classes=0)\n",
    "#         self.defect_branch = timm.create_model('swin_base_patch4_window7_224.ms_in22k_ft_in1k', pretrained=True, num_classes=0)\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.LayerNorm(2048),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(2048, 512),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(512, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, raw, defect):\n",
    "#         f_raw = self.raw_branch(raw)\n",
    "#         f_defect = self.defect_branch(defect)\n",
    "#         fused = torch.cat([f_raw, f_defect], dim=1)\n",
    "#         return self.classifier(fused)\n",
    "\n",
    "# def train_fusion(epochs=15, batch_size=12, lr=1e-4, accum_steps=2):  # accum_steps=2 → effective batch=24\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "\n",
    "#     train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "\n",
    "#     model = DualFusion(num_classes=9).to(device)\n",
    "#     criterion = FocalLoss(gamma=2.0).to(device)\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "#     scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "#     scaler = GradScaler()\n",
    "\n",
    "#     wandb.init(project=\"wm811k-fusion\", config={\"epochs\": epochs, \"batch_size\": batch_size, \"lr\": lr, \"accum_steps\": accum_steps, \"model\": \"Fusion-Safe\"})\n",
    "#     wandb.watch(model)\n",
    "\n",
    "#     best_val_acc = 0.0\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         train_loss = 0.0\n",
    "#         optimizer.zero_grad()\n",
    "#         for step, (raw, defect, labels) in enumerate(tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\")):\n",
    "#             raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "#             with autocast():\n",
    "#                 outputs = model(raw, defect)\n",
    "#                 loss = criterion(outputs, labels) / accum_steps  # Scale loss\n",
    "#             scaler.scale(loss).backward()\n",
    "#             train_loss += loss.item() * accum_steps\n",
    "\n",
    "#             if (step + 1) % accum_steps == 0 or (step + 1) == len(train_dl):\n",
    "#                 scaler.step(optimizer)\n",
    "#                 scaler.update()\n",
    "#                 optimizer.zero_grad()\n",
    "\n",
    "#         train_loss /= len(train_dl)\n",
    "\n",
    "#         model.eval()\n",
    "#         val_preds, val_labels = [], []\n",
    "#         val_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             for raw, defect, labels in tqdm(val_dl, desc=f\"Epoch {epoch+1}/{epochs} Val\"):\n",
    "#                 raw, defect, labels = raw.to(device), defect.to(device), labels.to(device)\n",
    "#                 with autocast():\n",
    "#                     outputs = model(raw, defect)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "#                 val_loss += loss.item()\n",
    "#                 preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "#                 val_preds.extend(preds)\n",
    "#                 val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#         val_loss /= len(val_dl)\n",
    "#         val_acc = accuracy_score(val_labels, val_preds)\n",
    "#         val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "\n",
    "#         wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss,\n",
    "#                    \"val_acc\": val_acc, \"val_macro_f1\": val_f1, \"lr\": scheduler.get_last_lr()[0]})\n",
    "\n",
    "#         print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f} | Val Loss {val_loss:.4f} | Val Acc {val_acc:.4f} | Val F1 {val_f1:.4f}\")\n",
    "\n",
    "#         if val_acc > best_val_acc:\n",
    "#             best_val_acc = val_acc\n",
    "#             torch.save(model.state_dict(), \"models/fusion_best.pth\")\n",
    "#             print(\"Saved best model!\")\n",
    "\n",
    "#         scheduler.step()\n",
    "\n",
    "#     train_dl.dataset.close()\n",
    "#     val_dl.dataset.close()\n",
    "#     print(\"Fusion done! Check WandB.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_fusion(epochs=1, batch_size=12, lr=1e-4, accum_steps=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = self.ce(logits, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        return ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "\n",
    "\n",
    "class DualFusion(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__()\n",
    "\n",
    "        # ↓↓↓ TINY MODELS (CRITICAL)\n",
    "        self.raw_branch = timm.create_model(\n",
    "            \"convnext_tiny\", pretrained=True, num_classes=0\n",
    "        )\n",
    "        self.defect_branch = timm.create_model(\n",
    "            \"swin_tiny_patch4_window7_224\", pretrained=True, num_classes=0\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(1536),   # 768 + 768\n",
    "            nn.Linear(1536, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, raw, defect):\n",
    "        f1 = self.raw_branch(raw)\n",
    "        f2 = self.defect_branch(defect)\n",
    "        return self.classifier(torch.cat([f1, f2], dim=1))\n",
    "\n",
    "\n",
    "def train_fusion(\n",
    "    epochs=15,\n",
    "    batch_size=4,        # SAFE\n",
    "    accum_steps=4,       # EFFECTIVE BATCH = 16\n",
    "    lr=1e-4\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_dl, val_dl, _ = get_dataloaders(batch_size)\n",
    "\n",
    "    model = DualFusion(num_classes=9).to(device)\n",
    "\n",
    "    # FREEZE DEFECT BRANCH (huge memory save)\n",
    "    for p in model.defect_branch.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    criterion = FocalLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=lr,\n",
    "        weight_decay=1e-2\n",
    "    )\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---------------- TRAIN ----------------\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for step, (raw, defect, labels) in enumerate(\n",
    "            tqdm(train_dl, desc=f\"Epoch {epoch+1}/{epochs} Train\")\n",
    "        ):\n",
    "            raw = raw.to(device, non_blocking=True)\n",
    "            defect = defect.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(raw, defect)\n",
    "                loss = criterion(outputs, labels) / accum_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % accum_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item() * accum_steps\n",
    "\n",
    "        train_loss /= len(train_dl)\n",
    "\n",
    "        # ---------------- VALIDATION ----------------\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for raw, defect, labels in tqdm(val_dl, desc=\"Validation\"):\n",
    "                raw = raw.to(device, non_blocking=True)\n",
    "                defect = defect.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                with autocast():\n",
    "                    outputs = model(raw, defect)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average=\"macro\")\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}: \"\n",
    "            f\"Train Loss={train_loss:.4f} | \"\n",
    "            f\"Val Loss={val_loss:.4f} | \"\n",
    "            f\"Acc={val_acc:.4f} | \"\n",
    "            f\"F1={val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"models/fusion_best.pth\")\n",
    "            print(\"✓ Saved best model\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(\"Training completed successfully.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_fusion(\n",
    "        epochs=1,\n",
    "        batch_size=4,\n",
    "        accum_steps=4,\n",
    "        lr=1e-4\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4339565b-d851-4c53-a226-a7a35f0d5b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
